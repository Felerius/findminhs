{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('pgf')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from bisect import bisect_left\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt, ticker\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = '\\n'.join([\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage{amsthm}',\n",
    "    r'\\usepackage{dsfont}',\n",
    "    r'\\usepackage[libertine,slantedGreek,vvarbb,libaltvw]{newtxmath}',\n",
    "    r'\\usepackage{url}',\n",
    "    r'\\usepackage{bm}',\n",
    "    r'\\usepackage[no-math]{fontspec}',\n",
    "    r'\\usepackage[ttscale=0.85]{libertine}',\n",
    "    r'\\usepackage[binary-units]{siunitx}',\n",
    "])\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "    'pgf.texsystem': 'lualatex',\n",
    "    'pgf.preamble': preamble,\n",
    "    'text.latex.preamble': preamble,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {\n",
       "        display: inline-block\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {\n",
    "        display: inline-block\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading & sanitizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_DIR_MAP = {\n",
    "    'cm': 'BS20',\n",
    "    'murakami_uno': 'MU13',\n",
    "    'thomas': 'Bir+20',\n",
    "    'vlrg': 'GV17',\n",
    "}\n",
    "instance_dir = Path('../../instances')\n",
    "full_path = {p.name: p.relative_to(instance_dir)\n",
    "             for p in instance_dir.glob('**/*')\n",
    "             if p.is_file()\n",
    "                 and p.suffix == '.dat'\n",
    "                 and p.relative_to(instance_dir).parts[0] != 'outdated'}\n",
    "instance_category = {name: CATEGORY_DIR_MAP[p.parts[0]] for name, p in full_path.items()}\n",
    "instances = list(instance_category.keys())\n",
    "categories = set(instance_category.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_variants = ['base', 'abs-pos']\n",
    "variants = [\n",
    "    'base',\n",
    "    'abs-pos',\n",
    "    'abs-neg',\n",
    "    'abs-sum',\n",
    "    'abs-max',\n",
    "    'rel-pos',\n",
    "    'rel-neg',\n",
    "    'rel-max',\n",
    "    'rel-sum',\n",
    "]\n",
    "\n",
    "\n",
    "def load_csv(path):\n",
    "    df = pd.read_csv(f'results/{path}.csv', index_col='file_name')\n",
    "    df = df[df.index.isin(full_path.keys())].copy()\n",
    "    # We track branching nodes + leaf nodes, which is always 2 * branching nodes + 1\n",
    "    # since it is a binary tree\n",
    "    df.iterations //= 2\n",
    "    return df\n",
    "\n",
    "\n",
    "df_class_base = pd.concat([load_csv(f'classification/base{suff}') for suff in ('', '-slow', '-really-slow', '-new')])\n",
    "df_class_abspos = pd.concat([load_csv(f'classification/abs-pos{suff}') for suff in ('', '-new')])\n",
    "\n",
    "# Add preliminary data for unfinished instance\n",
    "df_class_base.loc['cost_matrix_component_nr_118_size_204_cutoff_10.0.cm.dat'] = [None, None, None, 1443219, 648126579, None]\n",
    "\n",
    "df_fast_cand_base = pd.concat([load_csv(f'fast-candidates-10/base{suff}') for suff in ('', '-new')])\n",
    "df_fast_cand_abspos = pd.concat([load_csv(f'fast-candidates-10/abs-pos{suff}') for suff in ('', '-new')])\n",
    "\n",
    "df_easy_base = load_csv('easy-10/base')\n",
    "df_easy_abspos = load_csv('easy-10/abs-pos')\n",
    "\n",
    "df_base = pd.concat([df_class_base, df_fast_cand_base, df_easy_base])\n",
    "df_abspos = pd.concat([df_class_abspos, df_fast_cand_abspos, df_easy_abspos])\n",
    "\n",
    "hard_instances = set(df_abspos.index) - set(df_class_base[df_class_base.iterations < 500].index)\n",
    "all_easy_instances = set(df_base.index) - hard_instances\n",
    "base_counts = df_base[df_base.index.isin(hard_instances)].iterations.groupby('file_name').count()\n",
    "hard_fast_instances = set(base_counts[base_counts > 1].index)\n",
    "fully_reduced = set(df_class_base[df_class_base.iterations == 0].index)\n",
    "easy_instances = all_easy_instances - fully_reduced\n",
    "\n",
    "#unfinished_instances = hard_instances - set(df_base.index)\n",
    "assert(hard_instances - set(df_base.index) == set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name\n",
      "cost_matrix_component_nr_1032_size_115_cutoff_10.0.cm.dat    1046788.0\n",
      "cost_matrix_component_nr_1112_size_78_cutoff_10.0.cm.dat       15084.0\n",
      "cost_matrix_component_nr_362_size_99_cutoff_10.0.cm.dat         1456.0\n",
      "cost_matrix_component_nr_504_size_96_cutoff_10.0.cm.dat          775.0\n",
      "cost_matrix_component_nr_96_size_139_cutoff_10.0.cm.dat         8246.0\n",
      "Name: iterations, dtype: float64\n",
      "file_name\n",
      "cost_matrix_component_nr_1032_size_115_cutoff_10.0.cm.dat    12708\n",
      "cost_matrix_component_nr_1112_size_78_cutoff_10.0.cm.dat      1835\n",
      "cost_matrix_component_nr_362_size_99_cutoff_10.0.cm.dat       1070\n",
      "cost_matrix_component_nr_504_size_96_cutoff_10.0.cm.dat       1287\n",
      "cost_matrix_component_nr_96_size_139_cutoff_10.0.cm.dat       2833\n",
      "Name: iterations, dtype: int64\n",
      "file_name\n",
      "cost_matrix_component_nr_201_size_22_cutoff_10.0.cm.dat      1.0\n",
      "cost_matrix_component_nr_2183_size_43_cutoff_10.0.cm.dat    75.0\n",
      "cost_matrix_component_nr_2356_size_33_cutoff_10.0.cm.dat     9.0\n",
      "cost_matrix_component_nr_2715_size_13_cutoff_10.0.cm.dat     6.0\n",
      "cost_matrix_component_nr_835_size_27_cutoff_10.0.cm.dat      3.0\n",
      "Name: iterations, dtype: float64\n",
      "file_name\n",
      "cost_matrix_component_nr_201_size_22_cutoff_10.0.cm.dat      4\n",
      "cost_matrix_component_nr_2183_size_43_cutoff_10.0.cm.dat    17\n",
      "cost_matrix_component_nr_2356_size_33_cutoff_10.0.cm.dat    11\n",
      "cost_matrix_component_nr_2715_size_13_cutoff_10.0.cm.dat     5\n",
      "cost_matrix_component_nr_835_size_27_cutoff_10.0.cm.dat      3\n",
      "Name: iterations, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def five_instance_boxplots(ax, before, after, prop='iterations'):\n",
    "    improvements = before[prop].groupby('file_name').median() / after[prop].groupby('file_name').median()\n",
    "    improvements.sort_values(inplace=True)\n",
    "    n = len(improvements)\n",
    "    instances = [\n",
    "        improvements.index[0],\n",
    "        improvements.index[round(0.25 * n)],\n",
    "        improvements.index[round(0.5 * n)],\n",
    "        improvements.index[round(0.75 * n)],\n",
    "        improvements.index[-1],\n",
    "    ]\n",
    "    print(before.loc[instances].iterations.groupby('file_name').median())\n",
    "    print(after.loc[instances].iterations.groupby('file_name').median())\n",
    "    \n",
    "    data, pos = [], []\n",
    "    for i, name in enumerate(instances):\n",
    "        norm = before[prop].loc[name].median()\n",
    "        data.extend([\n",
    "            before[prop].loc[name] / norm,\n",
    "            after[prop].loc[name] / norm,\n",
    "        ])\n",
    "        pos.extend([3 * i + 1, 3 * i + 2])\n",
    "    ax.boxplot(data, positions=pos, flierprops=dict(markersize=2, markeredgewidth=0.25))\n",
    "    ax.set_xticks([3 * i + 1.5 for i in range(5)])\n",
    "    ax.set_xticks(pos, minor=True)\n",
    "    ax.set_xticklabels([r'\\texttt{base}', '\\\\texttt{abs-}\\n\\\\texttt{incl}'] * 5, fontdict=dict(fontsize='xx-small'), minor=True)\n",
    "    ax.tick_params(axis='x', which='minor', length=0)\n",
    "    ax.tick_params(axis='x', which='major', labelbottom=False)\n",
    "    ax.tick_params(axis='y', labelsize='xx-small')\n",
    "    ax.plot([0.5, 14.5], [1.0, 1.0], dashes=[3, 5], linewidth=0.5, zorder=-1, color='gray')\n",
    "    for i, t in enumerate(ax.get_xticklabels(minor=True)):\n",
    "        t.set_y(-0.02 if i % 2 else -0.06)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(4.858, 3), constrained_layout=True)\n",
    "five_instance_boxplots(axs[0],\n",
    "                       df_base[df_base.index.isin(hard_fast_instances)],\n",
    "                       df_abspos[df_abspos.index.isin(hard_fast_instances)])\n",
    "easy_before = df_base[~df_base.index.isin(hard_instances | fully_reduced)]\n",
    "easy_after = df_abspos[~df_abspos.index.isin(hard_instances | fully_reduced)]\n",
    "#names = {name for name in easy_before.index if df_class_base.loc[name].iterations >= 10}\n",
    "five_instance_boxplots(axs[1],\n",
    "                       easy_before,\n",
    "                       easy_after)\n",
    "\n",
    "axs[0].set_ylabel(r'\\texttt{hard-fast}', labelpad=19, fontsize='small')\n",
    "axs[1].set_ylabel(r'\\texttt{easy}', labelpad=19, fontsize='small')\n",
    "\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.tick_params(bottom=False, left=False, labelsize=0)\n",
    "plt.gca().set_ylabel(r'\\#br.\\ nodes (rel.\\ to median)', labelpad=19)\n",
    "\n",
    "# Incredibly hacky...\n",
    "plt.savefig('box-five-instance-both.pgf')\n",
    "bbox_top = axs[0].get_position()\n",
    "bbox_bot = axs[1].get_position()\n",
    "plt.gca().set_position([bbox_top.x0, bbox_bot.y0, bbox_top.x1 - bbox_top.x0, bbox_top.y1 - bbox_bot.y0])\n",
    "axs[0].set_ylabel(r'\\texttt{hard-fast}', labelpad=4)\n",
    "axs[1].set_ylabel(r'\\texttt{easy}', labelpad=4)\n",
    "fig.set_constrained_layout(False)\n",
    "plt.savefig('box-five-instance-both.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_base.loc[easy_instances], df_abspos.loc[easy_instances], df_base.loc[hard_fast_instances], df_abspos.loc[hard_fast_instances]]\n",
    "data = [df.iterations.groupby('file_name') for df in dfs]\n",
    "data = [df.std() / df.mean() for df in data]\n",
    "plt.figure(figsize=(1.8, 1.8))\n",
    "plt.ylabel(r'coefficient of variation', fontsize='small')\n",
    "ax = plt.gca()\n",
    "plt.boxplot(data, positions=[1.2, 1.8, 3.2, 3.8], flierprops=dict(markersize=2, markeredgewidth=0.25))\n",
    "ax.set_xticks([1.5, 3.5])\n",
    "ax.set_xticklabels([r'\\texttt{easy}', r'\\texttt{hard-fast}'], fontdict=dict(fontsize='small'))\n",
    "ax.set_xticks([1.1, 1.9, 3.1, 3.9], minor=True)\n",
    "ax.set_xticklabels([r'\\texttt{base}', '\\\\texttt{abs-}\\n\\\\texttt{incl}', r'\\texttt{base}', '\\\\texttt{abs-}\\n\\\\texttt{incl}'],\n",
    "                   fontdict=dict(fontsize='xx-small'),\n",
    "                   minor=True)\n",
    "ax.tick_params(axis='x', which='minor', length=0)\n",
    "ax.tick_params(axis='y', labelsize='small')\n",
    "for i, t in enumerate(ax.get_xticklabels()):\n",
    "    t.set_y(-0.1 if i else -0.115)\n",
    "for i, t in enumerate(ax.get_xticklabels(minor=True)):\n",
    "    t.set_y(0 if i % 2 else -0.03)\n",
    "plt.tight_layout()\n",
    "plt.savefig('box-coefficient-of-variation.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n"
     ]
    }
   ],
   "source": [
    "before_medians = df_base.iterations.groupby('file_name').median()\n",
    "after_medians = df_abspos.loc[df_base.index].iterations.groupby('file_name').median()\n",
    "\n",
    "plt.figure(figsize=(1.8, 2.5))\n",
    "ax = plt.gca()\n",
    "\n",
    "def at_least_names(mn):\n",
    "    return set(before_medians[before_medians >= mn].index)\n",
    "\n",
    "improv = before_medians / after_medians\n",
    "improv = improv[~improv.index.isin(hard_instances | fully_reduced)]\n",
    "print(len(improv[(0.5 <= improv) & (improv <= 2.0)]))\n",
    "data = [np.log2(improv[improv.index.isin(at_least_names(10**i))]) for i in range(3)]\n",
    "labels = [r'$\\geq 1$', r'$\\geq 10$', r'$\\geq 100$']\n",
    "plt.boxplot(data, labels=labels, flierprops=dict(markersize=2, markeredgewidth=0.25))\n",
    "\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: rf'$2^{{{int(x)}}}$'))\n",
    "plt.xlabel(r'\\texttt{base} [\\#br.\\ nodes]')\n",
    "plt.ylabel(r'improvement')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('box-improvements-easy.pgf')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/jacksonpradolima/f9b19d65b7f16603c837024d5f8c8a65\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "from bisect import bisect_left\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "from pandas import Categorical\n",
    "\n",
    "\n",
    "def VD_A(treatment: List[float], control: List[float]):\n",
    "    \"\"\"\n",
    "    Computes Vargha and Delaney A index\n",
    "    A. Vargha and H. D. Delaney.\n",
    "    A critique and improvement of the CL common language\n",
    "    effect size statistics of McGraw and Wong.\n",
    "    Journal of Educational and Behavioral Statistics, 25(2):101-132, 2000\n",
    "    The formula to compute A has been transformed to minimize accuracy errors\n",
    "    See: http://mtorchiano.wordpress.com/2014/05/19/effect-size-of-r-precision/\n",
    "    :param treatment: a numeric list\n",
    "    :param control: another numeric list\n",
    "    :returns the value estimate and the magnitude\n",
    "    \"\"\"\n",
    "    m = len(treatment)\n",
    "    n = len(control)\n",
    "\n",
    "    if m != n:\n",
    "        raise ValueError(\"Data d and f must have the same length\")\n",
    "\n",
    "    r = ss.rankdata(treatment + control)\n",
    "    r1 = sum(r[0:m])\n",
    "\n",
    "    # Compute the measure\n",
    "    # A = (r1/m - (m+1)/2)/n # formula (14) in Vargha and Delaney, 2000\n",
    "    A = (2 * r1 - m * (m + 1)) / (2 * n * m)  # equivalent formula to avoid accuracy errors\n",
    "\n",
    "    levels = [0.147, 0.33, 0.474]  # effect sizes from Hess and Kromrey, 2004\n",
    "    magnitude = [\"negligible\", \"small\", \"medium\", \"large\"]\n",
    "    scaled_A = (A - 0.5) * 2\n",
    "\n",
    "    magnitude = magnitude[bisect_left(levels, abs(scaled_A))]\n",
    "    estimate = A\n",
    "\n",
    "    return estimate, magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(name, bef, aft, prop):\n",
    "    after = aft[prop]\n",
    "    base = bef[prop]\n",
    "    u = mannwhitneyu(after, base, True, 'less')\n",
    "    u_inv = mannwhitneyu(after, base, True, 'greater')\n",
    "    return (shorten_name(name), u, u_inv, VD_A(list(after), list(base)))\n",
    "\n",
    "def analyze_all(bef, aft):\n",
    "    names = list(bef.index.unique())\n",
    "    data_iterations = sorted((analyze(name, bef.loc[name], aft.loc[name], 'iterations') for name in names), key=lambda t: t[1].pvalue)\n",
    "    data_time = sorted((analyze(name, bef.loc[name], aft.loc[name], 'solve_time') for name in names), key=lambda t: t[1].pvalue)\n",
    "    return data_iterations, data_time\n",
    "\n",
    "analyze_all(base_fast, abspos_fast)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast candidates (194 instances, 11 runs per instance)\n",
    "\n",
    "#### Iterations\n",
    "\n",
    "* 4x: significant large increase\n",
    "* 15x: insignificant change (medium increase to medium reduction)\n",
    "* 2x: significant medium reduction\n",
    "* 173x: significant large reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before/After Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def before_after_scatterplot(before,\n",
    "                             after,\n",
    "                             prop='iterations',\n",
    "                             agg='median',\n",
    "                             log=True,\n",
    "                             mn=1,\n",
    "                             xlabel=r'\\texttt{base} [\\#br.\\ nodes]',\n",
    "                             ylabel=r'\\texttt{abs-incl} [\\#br.\\ nodes]',\n",
    "                             legendloc='best',\n",
    "                             highlight=None,\n",
    "                             highlight_label=None,\n",
    "                             no_highlight_label=None,\n",
    "                             figsize=(3, 3),\n",
    "                             legendfontsize='medium',\n",
    "                             linear_regression=False):\n",
    "    COLORS = ['#e66101','#fdb863','#b2abd2','#5e3c99']\n",
    "    \n",
    "    x = before[prop].groupby('file_name').median().sort_index()\n",
    "    y = after[prop].groupby('file_name').median().sort_index()\n",
    "    highlight = set(highlight or [])\n",
    "    x_no_highlight, y_no_highlight = x[~x.index.isin(highlight)], y[~y.index.isin(highlight)]\n",
    "    x_highlight, y_highlight = x[x.index.isin(highlight)], y[y.index.isin(highlight)]\n",
    "    \n",
    "    category_colors = {cat: COLORS[i] for i, cat in enumerate(sorted(categories, key=lambda s: s.lower()))}\n",
    "    appearing_categories = {instance_category[name] for name in x.index}\n",
    "    mx = (1.5 if log else 1.05) * max(x.max(), y.max())\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.gca()\n",
    "    if log:\n",
    "        logtype = 'symlog' if mn <= 0 else 'log'\n",
    "        plt.xscale(logtype)\n",
    "        plt.yscale(logtype)\n",
    "    plt.xlim([mn, mx])\n",
    "    plt.ylim([mn, mx])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    locmaj = ticker.LogLocator(base=10, numticks=100)\n",
    "    locmin = ticker.LogLocator(base=10, subs=np.arange(1, 10) / 10, numticks=100)\n",
    "    for axis in (ax.xaxis, ax.yaxis):\n",
    "        axis.set_major_locator(locmaj)\n",
    "        axis.set_minor_locator(locmin)\n",
    "        axis.set_minor_formatter(ticker.NullFormatter())\n",
    "        #axis.set_ticks_position('both')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "    highlight = set(highlight or [])\n",
    "    plt.scatter(x_no_highlight,\n",
    "                y_no_highlight, \n",
    "                c=[category_colors[instance_category[name]] for name in x_no_highlight.index],\n",
    "                s=3.0**2,\n",
    "                linewidth=0.25,\n",
    "                edgecolor='black',\n",
    "                alpha=1)\n",
    "    plt.scatter(x_highlight,\n",
    "                y_highlight, \n",
    "                c=[category_colors[instance_category[name]] for name in x_highlight.index],\n",
    "                s=3.0**2,\n",
    "                marker='s',\n",
    "                linewidth=0.4,\n",
    "                edgecolor='black',\n",
    "                alpha=1)\n",
    "    \n",
    "    def line(x1, y1, x2, y2, **kwargs):\n",
    "        plt.plot([x1, x2], [y1, y2], color='black', zorder=-1, **kwargs)\n",
    "    line(mn, mn, mx, mx, linewidth=0.8)\n",
    "    base=10\n",
    "    if log:\n",
    "        for i in range(1, 100):\n",
    "            if base**i > mx:\n",
    "                break\n",
    "            line(mn, mn * base**i, mx / base**i, mx, dashes=[3, 5], linewidth=.5)\n",
    "            line(mn * base**i, mn, mx, mx / base**i, dashes=[3, 5], linewidth=.5)\n",
    "    \n",
    "    legend_handles = [Patch(color=col, label=r'\\texttt{' + cat + '}') for cat, col in category_colors.items() if cat in appearing_categories]\n",
    "    if highlight:\n",
    "        for edgewidth, marker, label in [(0.5, 'o', no_highlight_label), (0.8, 's', highlight_label)]:\n",
    "            legend_handles.append(Line2D([], [], color='lightgrey', marker=marker, linestyle='None',\n",
    "                                         markeredgecolor='black', markeredgewidth=edgewidth,\n",
    "                                         markersize=6, label=label))\n",
    "    plt.legend(handles=legend_handles,\n",
    "               loc=legendloc,\n",
    "               fontsize=legendfontsize)\n",
    "    \n",
    "    if linear_regression:\n",
    "        assert log\n",
    "        regr_x = sm.add_constant(np.log(x))\n",
    "        regr_y = np.log(y)\n",
    "        model = sm.OLS(regr_y, regr_x)\n",
    "        res = model.fit()\n",
    "        print(res.summary())\n",
    "        pred_x = np.linspace(np.log(mn), np.log(mx), 100)\n",
    "        sf = res.get_prediction(sm.add_constant(pred_x)).summary_frame(alpha=0.05)\n",
    "        plt.plot(np.exp(pred_x), np.exp(sf['mean']), zorder=1, linewidth=0.8, color=COLORS[3])\n",
    "        plt.fill_between(np.exp(pred_x),\n",
    "                         np.exp(sf['mean_ci_lower']),\n",
    "                         np.exp(sf['mean_ci_upper']),\n",
    "                         alpha=0.5,\n",
    "                         zorder=1,\n",
    "                         color=COLORS[3],\n",
    "                         linewidth=0)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df_base[df_base.index.isin(hard_finished_instances)]\n",
    "after = df_abspos[df_abspos.index.isin(hard_finished_instances)]\n",
    "counts = before.iterations.groupby('file_name').count()\n",
    "only_single_run = list(counts[counts == 1].index)\n",
    "before_after_scatterplot(before, \n",
    "                         after,\n",
    "                         mn = 100,\n",
    "                         legendloc='upper left',\n",
    "                         legendfontsize='x-small',\n",
    "                         highlight=only_single_run,\n",
    "                         no_highlight_label=r'\\texttt{hard-fast}',\n",
    "                         highlight_label=r'\\texttt{hard-slow}',\n",
    "                         figsize=(2.429, 2.429))\n",
    "plt.savefig('scatter-branching-nodes-hard.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             iterations   R-squared:                       0.892\n",
      "Model:                            OLS   Adj. R-squared:                  0.892\n",
      "Method:                 Least Squares   F-statistic:                     1508.\n",
      "Date:                Fri, 05 Feb 2021   Prob (F-statistic):           5.33e-90\n",
      "Time:                        11:15:08   Log-Likelihood:                -179.15\n",
      "No. Observations:                 184   AIC:                             362.3\n",
      "Df Residuals:                     182   BIC:                             368.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.0462      0.158     12.976      0.000       1.735       2.357\n",
      "iterations     0.6015      0.015     38.832      0.000       0.571       0.632\n",
      "==============================================================================\n",
      "Omnibus:                        0.727   Durbin-Watson:                   1.840\n",
      "Prob(Omnibus):                  0.695   Jarque-Bera (JB):                0.423\n",
      "Skew:                          -0.074   Prob(JB):                        0.809\n",
      "Kurtosis:                       3.182   Cond. No.                         34.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "names = {name for name in hard_finished_instances if instance_category[name] != 'MU13'}\n",
    "before = df_base[df_base.index.isin(names)]\n",
    "after = df_abspos[df_abspos.index.isin(names)]\n",
    "counts = before.iterations.groupby('file_name').count()\n",
    "only_single_run = list(counts[counts == 1].index)\n",
    "before_after_scatterplot(before, \n",
    "                         after,\n",
    "                         mn = 100,\n",
    "                         legendloc='upper left',\n",
    "                         legendfontsize='x-small',\n",
    "                         highlight=only_single_run,\n",
    "                         no_highlight_label=r'\\texttt{hard-fast}',\n",
    "                         highlight_label=r'\\texttt{hard-slow}',\n",
    "                         linear_regression=True,\n",
    "                         figsize=(2.429, 2.429))\n",
    "plt.savefig('scatter-branching-nodes-hard-regression.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df_base[~df_base.index.isin(hard_instances | fully_reduced)]\n",
    "after = df_abspos[~df_abspos.index.isin(hard_instances | fully_reduced)]\n",
    "before_after_scatterplot(before,\n",
    "                         after,\n",
    "                         figsize=(2.429, 2.429),\n",
    "                         legendloc='upper left',\n",
    "                         legendfontsize='x-small')\n",
    "plt.savefig('scatter-branching-nodes-easy.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs20 = {name for name in instances if instance_category[name] == 'BS20'}\n",
    "before = df_base[~df_base.index.isin(hard_instances | fully_reduced | bs20)]\n",
    "after = df_abspos[~df_abspos.index.isin(hard_instances | fully_reduced | bs20)]\n",
    "before_after_scatterplot(before,\n",
    "                         after,\n",
    "                         figsize=(2.429, 2.429),\n",
    "                         legendloc='upper left',\n",
    "                         legendfontsize='x-small')\n",
    "plt.savefig('scatter-branching-nodes-easy-no-bs20.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df_base[df_base.index.isin(hard_finished_instances)]\n",
    "after = df_abspos[df_abspos.index.isin(hard_finished_instances)]\n",
    "counts = before.iterations.groupby('file_name').count()\n",
    "only_single_run = list(counts[counts == 1].index)\n",
    "before_after_scatterplot(before, \n",
    "                         after,\n",
    "                         mn = 0.1,\n",
    "                         prop='solve_time',\n",
    "                         legendloc='upper left',\n",
    "                         legendfontsize='xx-small',\n",
    "                         xlabel=r'\\texttt{base} [s]',\n",
    "                         ylabel=r'\\texttt{abs-incl} [s]',\n",
    "                         highlight=only_single_run,\n",
    "                         no_highlight_label=r'\\texttt{hard-fast}',\n",
    "                         highlight_label=r'\\texttt{hard-slow}',\n",
    "                         figsize=(2.429, 2.429))\n",
    "plt.savefig('scatter-runtime-hard.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "154196.94061529092\n",
      "1009069.7600713499\n",
      "80821.333990683\n",
      "145069.76007135015\n",
      "Avg iterations improvement for trivial: 1.0424554931154455\n",
      "Avg iterations improvement for trivial >= 10: 1.2797001743086387\n",
      "Avg iterations improvement for trivial >= 100: 1.5357183287806604\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "bef = dfs_class['base'].iterations\n",
    "aft = dfs_class['abs-pos'].iterations\n",
    "bef_time = dfs_class['base'].solve_time\n",
    "aft_time = dfs_class['abs-pos'].solve_time\n",
    "\n",
    "candidates = [name for name in instances if name in aft.index and (name not in bef.index or bef.loc[name] >= 1000)]\n",
    "print(len(candidates))\n",
    "print(sum(aft_time[name] for name in candidates))\n",
    "print(sum(bef_time.get(name, 12 * 60 * 60) for name in candidates))\n",
    "print(sum(aft_time[name] for name in candidates if name in bef.index))\n",
    "print(sum(bef_time[name] for name in candidates if name in bef.index))\n",
    "\n",
    "fast_candidates = [name for name in candidates if name in bef.index]\n",
    "slow_candidates = [name for name in candidates if name not in bef.index]\n",
    "#Path('../fast-candidates.txt').write_text('\\n'.join(str(full_path[name]) for name in fast_candidates))\n",
    "#Path('../slow-candidates.txt').write_text('\\n'.join(str(full_path[name]) for name in slow_candidates))\n",
    "\n",
    "trivial = [name for name in instances if bef.get(name, 1000) < 1000]\n",
    "trivial_least_10 = [name for name in trivial if bef.loc[name] >= 10]\n",
    "trivial_least_100 = [name for name in trivial if bef.loc[name] >= 100]\n",
    "print(f'Avg iterations improvement for trivial:', sum(bef.get(name) / aft.get(name) for name in trivial) / len(trivial))\n",
    "print(f'Avg iterations improvement for trivial >= 10:', sum(bef.get(name) / aft.get(name) for name in trivial_least_10) / len(trivial_least_10))\n",
    "print(f'Avg iterations improvement for trivial >= 100:', sum(bef.get(name) / aft.get(name) for name in trivial_least_100) / len(trivial_least_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance classification\n",
    "\n",
    "### (Too) few iterations\n",
    "\n",
    "* 3793x: fewer than 100 its w/o activity\n",
    "* 4016x: fewer than 1000 its w/o activity\n",
    "\n",
    "### Long runtime\n",
    "\n",
    "* 63x: did not finish in 3h w/ or w/o activity\n",
    "* 20x: did not finish w/o activity but finished with\n",
    "  * 8x: did not finish in 1h w/ activity\n",
    "\n",
    "-> 206 candidates for running experiments (finished w/ activity in 1h and >= 1000 its w/o activity)\n",
    "\n",
    "### Instance types\n",
    "\n",
    "| | vlrg | murakami_uno | konect_bip | cm | thomas | enumdat |\n",
    "|-|------|--------------|------------|----|--------|---------|\n",
    "| candidate | 0 | 30 | 0 | 173 | 3 | 0 |\n",
    "| <1000 its | 29 | 101 | 16 | 3727 | 131 | 12 |\n",
    "| too slow | 0 | 9 | 10 | 52 | 0 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slow_24 = pd.read_csv('./results/classification/base-slow.csv', index_col='file_name')\n",
    "def format_runtime(secs):\n",
    "    return f'{int(secs) // 60**2:02}:{int(round(int(secs) % 60**2 / 60)):02}'\n",
    "\n",
    "for name in slow_candidates:\n",
    "    its_aft = dfs_class['abs-pos'].loc[name].iterations\n",
    "    time_aft = dfs_class['abs-pos'].loc[name].solve_time\n",
    "    if name in df_slow_24.index:\n",
    "        its_bef = df_slow_24.loc[name].iterations\n",
    "        time_bef = df_slow_24.loc[name].solve_time\n",
    "        time_speed_up = f'{time_bef / time_aft:.2f}'\n",
    "        its_speed_up = f'{its_bef / its_aft:.2f}'\n",
    "        its_bef, time_bef = str(its_bef), format_runtime(time_bef)\n",
    "    else:\n",
    "        time_bef = '>24:00'\n",
    "        its_bef = '-'\n",
    "        time_speed_up = f'>{24 * 60**2 / time_aft:.2f}'\n",
    "        its_speed_up = '-'\n",
    "    print('|', ' | '.join([shorten_name(name), time_bef, format_runtime(time_aft), time_speed_up, its_bef, str(its_aft), its_speed_up]), '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| name | before | after | speed up | before | after | speed up |\n",
    "|-|-|-|-|-|-|-|\n",
    "| nr_130_size_289 | 03:14 | 00:39 | 4.99 | 448641 | 21825 | 20.56 |\n",
    "| nr_487_size_113 | 03:17 | 00:01 | 175.79 | 15774187 | 90889 | 173.55 |\n",
    "| nr_493_size_263 | 04:59 | 00:43 | 6.96 | 646907 | 17965 | 36.01 |\n",
    "| nr_54_size_279 | 06:25 | 01:38 | 3.93 | 1395789 | 64857 | 21.52 |\n",
    "| nr_1751_size_144 | 07:51 | 00:09 | 51.30 | 5820373 | 82849 | 70.25 |\n",
    "| nr_758_size_127 | 08:57 | 00:08 | 67.22 | 19003071 | 220359 | 86.24 |\n",
    "| nr_95_size_134 | 09:60 | 00:23 | 25.94 | 34298865 | 1348593 | 25.43 |\n",
    "| nr_241_size_252 | 11:24 | 02:48 | 4.08 | 14767953 | 119031 | 124.07 |\n",
    "| nr_385_size_217 | 12:32 | 00:15 | 49.32 | 4570381 | 39207 | 116.57 |\n",
    "| nr_794_size_163 | 13:48 | 01:01 | 13.54 | 13060125 | 869011 | 15.03 |\n",
    "| nr_163_size_122 | 17:17 | 00:20 | 52.00 | 71952883 | 809753 | 88.86 |\n",
    "| nr_789_size_150 | 19:26 | 00:28 | 41.14 | 36261777 | 465771 | 77.85 |\n",
    "| nr_525_size_215 | 20:38 | 02:17 | 9.03 | 7043685 | 254567 | 27.67 |\n",
    "| nr_279_size_209 | 22:46 | 01:30 | 15.14 | 7123757 | 173723 | 41.01 |\n",
    "| nr_209_size_160 | 31:13 | 00:37 | 51.14 | 69918283 | 809703 | 86.35 |\n",
    "| nr_123_size_148 | 45:31 | 00:08 | 341.42 | 64041167 | 76451 | 837.68 |\n",
    "| nr_43_size_345 | 47:41 | 02:56 | 16.23 | 4520973 | 125247 | 36.1 |\n",
    "| nr_92_size_194 | 61:56 | 01:48 | 34.26 | 27503137 | 480469 | 57.24 |\n",
    "| nr_74_size_223 | 145:14| 01:54 | 76.24 | 39129927 | 322911 | 121.18 |\n",
    "| nr_118_size_204 | >24:00 | 00:39 | >37.31 | - | 2774675 | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement vs. Speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    184.000000\n",
      "mean       0.718298\n",
      "std        0.266358\n",
      "min        0.032887\n",
      "25%        0.552681\n",
      "50%        0.719602\n",
      "75%        0.881303\n",
      "max        1.475097\n",
      "dtype: float64\n",
      "0.1523072282865475\n",
      ">=1: 25\n",
      ">=0.75: 82\n",
      ">=0.5: 148\n",
      "0.1523072282865475\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(2.429, 2.429))\n",
    "\n",
    "before_hard_fast = df_base.loc[hard_fast_instances].groupby('file_name').median()\n",
    "after_hard_fast = df_abspos.loc[hard_fast_instances].groupby('file_name').median()\n",
    "before_hard_slow = df_base.loc[hard_finished_instances - hard_fast_instances].groupby('file_name').median()\n",
    "after_hard_slow = df_abspos.loc[hard_finished_instances - hard_fast_instances].groupby('file_name').median()\n",
    "\n",
    "fast_it = before_hard_fast.iterations / after_hard_fast.iterations\n",
    "fast_ti = before_hard_fast.solve_time / after_hard_fast.solve_time\n",
    "slow_it = before_hard_slow.iterations / after_hard_slow.iterations\n",
    "slow_ti = before_hard_slow.solve_time / after_hard_slow.solve_time\n",
    "\n",
    "mn = 0.1\n",
    "mx = 1.5 * max(fast_it.max(), fast_ti.max(), slow_it.max(), slow_ti.max())\n",
    "ax = plt.gca()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim([mn, mx])\n",
    "plt.ylim([mn, mx])\n",
    "locmaj = ticker.LogLocator(base=10, numticks=100)\n",
    "locmin = ticker.LogLocator(base=10, subs=np.arange(1, 10) / 10, numticks=100)\n",
    "for axis in (ax.xaxis, ax.yaxis):\n",
    "    axis.set_major_locator(locmaj)\n",
    "    axis.set_minor_locator(locmin)\n",
    "    axis.set_minor_formatter(ticker.NullFormatter())\n",
    "ax.set_aspect('equal', 'box')\n",
    "\n",
    "COLORS = ['#e66101','#fdb863','#b2abd2','#5e3c99']\n",
    "category_colors = {cat: COLORS[i] for i, cat in enumerate(sorted(categories, key=lambda s: s.lower()))}\n",
    "appearing_categories = {instance_category[name] for name in hard_finished_instances}\n",
    "legend_handles = [Patch(color=col, label=r'\\texttt{' + cat + '}') for cat, col in category_colors.items() if cat in appearing_categories]\n",
    "for edgewidth, marker, label in [(0.5, 'o', r'\\texttt{hard-fast}'), (0.8, 's', r'\\texttt{hard-slow}')]:\n",
    "    legend_handles.append(Line2D([], [], color='lightgrey', marker=marker, linestyle='None',\n",
    "                                 markeredgecolor='black', markeredgewidth=edgewidth,\n",
    "                                 markersize=6, label=label))\n",
    "plt.legend(handles=legend_handles,\n",
    "           loc='lower right',\n",
    "           fontsize='xx-small')\n",
    "\n",
    "plt.scatter(fast_ti,\n",
    "            fast_it, \n",
    "            c=[category_colors[instance_category[name]] for name in before_hard_fast.index],\n",
    "            s=3.0**2,\n",
    "            linewidth=0.25,\n",
    "            edgecolor='black')\n",
    "plt.scatter(slow_ti,\n",
    "            slow_it,\n",
    "            c=[category_colors[instance_category[name]] for name in before_hard_slow.index],\n",
    "            s=3.0**2,\n",
    "            marker='s',\n",
    "            linewidth=0.4,\n",
    "            edgecolor='black')\n",
    "\n",
    "plt.xlabel('speed up')\n",
    "plt.ylabel('improvement')\n",
    "\n",
    "def line(x1, y1, x2, y2, **kwargs):\n",
    "    plt.plot([x1, x2], [y1, y2], color='black', zorder=-1, **kwargs)\n",
    "line(mn, mn, mx, mx, linewidth=0.8)\n",
    "base=10\n",
    "for i in range(1, 100):\n",
    "    if base**i > mx:\n",
    "        break\n",
    "    line(mn, mn * base**i, mx / base**i, mx, dashes=[3, 5], linewidth=.5)\n",
    "    line(mn * base**i, mn, mx, mx / base**i, dashes=[3, 5], linewidth=.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scatter-improvement-vs-speed-up-hard.pgf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(2.4, 5))\n",
    "improvement_speedup_ratio = pd.concat([fast_ti, slow_ti]) / pd.concat([fast_it, slow_it])\n",
    "plt.yscale('log')\n",
    "plt.boxplot([improvement_speedup_ratio], flierprops=dict(markersize=2, markeredgewidth=0.25))\n",
    "plt.tight_layout()\n",
    "plt.savefig('test2.pdf')\n",
    "plt.close()\n",
    "\n",
    "f = np.vectorize(lambda name: instance_category[name])\n",
    "improvement_speedup_ratio = improvement_speedup_ratio[(f(improvement_speedup_ratio.index) != 'MU13')]\n",
    "print(improvement_speedup_ratio.describe())\n",
    "print(improvement_speedup_ratio.sort_values()[1])\n",
    "print('>=1:', len(improvement_speedup_ratio[improvement_speedup_ratio >= 1]))\n",
    "print('>=0.75:', len(improvement_speedup_ratio[improvement_speedup_ratio >= 0.75]))\n",
    "print('>=0.5:', len(improvement_speedup_ratio[improvement_speedup_ratio >= 0.5]))\n",
    "print(improvement_speedup_ratio.sort_values()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([name for name in hard_instances if instance_category[name] == 'MU13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BS20</th>\n",
       "      <td>181.0</td>\n",
       "      <td>22.289923</td>\n",
       "      <td>74.365691</td>\n",
       "      <td>0.602176</td>\n",
       "      <td>2.171582</td>\n",
       "      <td>4.207729</td>\n",
       "      <td>15.043373</td>\n",
       "      <td>837.686933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bir+20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.315677</td>\n",
       "      <td>3.222153</td>\n",
       "      <td>1.596585</td>\n",
       "      <td>4.339713</td>\n",
       "      <td>7.082840</td>\n",
       "      <td>7.175223</td>\n",
       "      <td>7.267606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU13</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.223185</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>0.761491</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>1.013387</td>\n",
       "      <td>1.047971</td>\n",
       "      <td>5.216520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std       min       25%       50%        75%  \\\n",
       "BS20    181.0  22.289923  74.365691  0.602176  2.171582  4.207729  15.043373   \n",
       "Bir+20    3.0   5.315677   3.222153  1.596585  4.339713  7.082840   7.175223   \n",
       "MU13     32.0   1.223185   0.797749  0.761491  0.999865  1.013387   1.047971   \n",
       "\n",
       "               max  \n",
       "BS20    837.686933  \n",
       "Bir+20    7.267606  \n",
       "MU13      5.216520  "
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_medians = df_base.iterations.groupby('file_name').median()\n",
    "after_medians = df_abspos.loc[df_base.index].iterations.groupby('file_name').median()\n",
    "improv = before_medians / after_medians\n",
    "improv[improv.index.isin(hard_instances)].groupby(lambda name: instance_category[name]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1: 5\n",
      ">=10: 59\n",
      "count    184.000000\n",
      "mean      22.013169\n",
      "std       73.785879\n",
      "min        0.602176\n",
      "25%        2.166705\n",
      "50%        4.239436\n",
      "75%       15.032397\n",
      "max      837.686933\n",
      "Name: iterations, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "before_medians = df_base.iterations.groupby('file_name').median()\n",
    "after_medians = df_abspos.loc[df_base.index].iterations.groupby('file_name').median()\n",
    "improv = before_medians / after_medians\n",
    "f = np.vectorize(lambda name: instance_category[name])\n",
    "non_random = improv[(f(improv.index) != 'MU13') & improv.index.isin(hard_instances)]\n",
    "print('<1:', len(non_random[non_random < 1.0]))\n",
    "print('>=10:', len(non_random[non_random >= 10]))\n",
    "print(non_random.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1: 22\n",
      ">=10: 42\n",
      "count    184.000000\n",
      "mean      14.820053\n",
      "std       54.684237\n",
      "min        0.445792\n",
      "25%        1.507324\n",
      "50%        3.134512\n",
      "75%        8.801426\n",
      "max      623.200692\n",
      "Name: solve_time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "before_medians = df_base.solve_time.groupby('file_name').median()\n",
    "after_medians = df_abspos.loc[df_base.index].solve_time.groupby('file_name').median()\n",
    "improv = before_medians / after_medians\n",
    "f = np.vectorize(lambda name: instance_category[name])\n",
    "non_random = improv[(f(improv.index) != 'MU13') & improv.index.isin(hard_instances)]\n",
    "print('<1:', len(non_random[non_random < 1.0]))\n",
    "print('>=10:', len(non_random[non_random >= 10]))\n",
    "print(non_random.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
