{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from __future__ import annotations\n",
    "import contextlib\n",
    "import json\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Instances are considered \"hard\" if solving them takes >= MIN_HARD_SECS seconds\n",
    "MIN_HARD_SECS = 1\n",
    "\n",
    "# Timeout for all runs, in seconds\n",
    "EXPERIMENT_TIMEOUT = 24 * 60**2\n",
    "\n",
    "random_instance_regex = re.compile(r'p\\d+_\\d+\\.dat')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Consolidate results\n",
    "\n",
    "Generates combined files that make executing this notebook a 2nd/3rd/... time much faster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine findminhs JSON files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "result_dirs = [d for d in Path('results').glob('*') if d.is_dir()]\n",
    "for results_dir in tqdm(result_dirs, desc='Combining experiment json files'):\n",
    "    data = [json.loads(f.read_text()) for f in results_dir.glob('**/*.json')]\n",
    "    with Path(f'results/{results_dir.name}.json').open('w') as f:\n",
    "        json.dump(data, f)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Combining experiment json files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f3948c7909a47ec9d4dcbbb4fd3d74d"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate `instance-sizes.json`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_instance_size(p: Path) -> int:\n",
    "    with p.open() as f:\n",
    "        # Skip initial line containing node and edge count\n",
    "        next(f)\n",
    "        return sum(int(line.split(maxsplit=1)[0]) for line in f)\n",
    "\n",
    "\n",
    "instances = list(Path('instances').glob('*.dat'))\n",
    "instance_sizes = {\n",
    "    f.name: get_instance_size(f)\n",
    "    for f in tqdm(instances, desc='Determining instances size')\n",
    "}\n",
    "with open('instance-sizes.json', 'w') as f:\n",
    "    json.dump(instance_sizes, f)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Determining instances size:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9978f7fa09174133848cff3279a9d54a"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instance info"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "all_instance_names = [f.name for f in Path('instances').glob('*.dat')]\n",
    "with open('instance-sizes.json') as f:\n",
    "    instance_size = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Findminhs results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def load_combined_json(path: Path) -> pd.DataFrame:\n",
    "    with path.open() as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.json_normalize(data, sep='__').rename(\n",
    "        columns=lambda col: col[2:] if col.startswith('__') else col)\n",
    "    df.set_index('file_name', inplace=True)\n",
    "    return df.reindex(all_instance_names)\n",
    "\n",
    "\n",
    "json_files = list(Path('results').glob('*.json'))\n",
    "dfs_by_experiment = {\n",
    "    f.stem: load_combined_json(f)\n",
    "    for f in tqdm(json_files, desc='Loading experiment data')\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading experiment data:   0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b76a16abd3cb452f90a6f3aa795583ce"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gurobi results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Gurobi log parsing\n",
    "GUROBI_REGEXES = [\n",
    "    re.compile(regex, re.MULTILINE) for regex in (\n",
    "        r'^Presolve time: (.*)s$',\n",
    "        r'^Root relaxation: .*?, .*? iterations, (.*?) seconds$',\n",
    "        r'^Explored .*? nodes \\(.*? simplex iterations\\) in (.*?) seconds$',\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def gurobi_parse_time(log_file: Path) -> Optional[float]:\n",
    "    text = Path(log_file).read_text()\n",
    "    matches = [regex.search(text) for regex in GUROBI_REGEXES]\n",
    "    # Solving finished if the last message matched by the last regex appears\n",
    "    if matches[-1] is None:\n",
    "        return None\n",
    "    return sum(float(m[1]) for m in matches if m is not None)\n",
    "\n",
    "\n",
    "def load_gurobi_runtimes(directory: Path) -> pd.Series:\n",
    "    logs = list(directory.glob('*.log'))\n",
    "    runtimes = {(f.stem + '.dat'): gurobi_parse_time(f)\n",
    "                for f in tqdm(logs, desc='Analysing gurobi logs')}\n",
    "    series = pd.Series(runtimes, dtype=np.float64)\n",
    "    return series.reindex(all_instance_names)\n",
    "\n",
    "\n",
    "gurobi_df = load_gurobi_runtimes(Path('gurobi-logs'))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Analysing gurobi logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a379aab77a2409987fb52da1f1280d9"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduced Gurobi results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def load_log(p: Path) -> dict:\n",
    "    with p.open() as f:\n",
    "        data = json.load(f)\n",
    "    data['file_name'] = p.with_suffix('.dat').name\n",
    "    return data\n",
    "\n",
    "\n",
    "reduction_logs = list(Path('reduction-logs').glob('*.json'))\n",
    "logs = [\n",
    "    load_log(p) for p in tqdm(reduction_logs, desc='Loading reduction logs')\n",
    "]\n",
    "gurobi_reduced_df = pd.DataFrame(logs)\n",
    "gurobi_reduced_df.set_index('file_name', inplace=True)\n",
    "gurobi_reduced_df = gurobi_reduced_df.reindex(all_instance_names)\n",
    "gurobi_reduced_df.runtime += load_gurobi_runtimes(Path('gurobi-reduced-logs'))\n",
    "\n",
    "vs_nonreduced = gurobi_reduced_df.runtime / gurobi_df\n",
    "vs_nonreduced = vs_nonreduced[vs_nonreduced.index.map(\n",
    "    lambda name: gurobi_df.loc[name] >= MIN_HARD_SECS)]\n",
    "improved = len(vs_nonreduced[vs_nonreduced < 0.5])\n",
    "deteriorated = len(vs_nonreduced[vs_nonreduced > 2.0])\n",
    "print(f'{improved} better by at least 2x, {deteriorated} worse by at least 2x')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading reduction logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86ab3e1de5a84243aa678fbab725423a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Analysing gurobi logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9570a570ded457183cafb315792aa1f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40 better by at least 2x, 10 worse by at least 2x\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instance classification (easy/hard)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Hard instance for solver: required >= MIN_HARD_SECS seconds to finish\n",
    "# Easy: not hard\n",
    "\n",
    "df = dfs_by_experiment['default']\n",
    "easy_instances_findminhs = set(df[df.runtimes__total < MIN_HARD_SECS].index)\n",
    "easy_instances_gurobi = set(gurobi_df[gurobi_df < MIN_HARD_SECS].index)\n",
    "easy_instances_both = easy_instances_findminhs & easy_instances_gurobi\n",
    "hard_instances_findminhs = set(all_instance_names) - easy_instances_findminhs\n",
    "\n",
    "num_hard_finished_findminhs = len(df[df.runtimes__total.notna()\n",
    "                                     & (df.runtimes__total >= MIN_HARD_SECS)])\n",
    "num_hard_finished_gurobi = len(gurobi_df[gurobi_df.notna()\n",
    "                                         & (gurobi_df >= MIN_HARD_SECS)])\n",
    "unfinished_findminhs = set(df[df.runtimes__total.isna()].index)\n",
    "unfinished_gurobi = set(gurobi_df[gurobi_df.isna()].index)\n",
    "\n",
    "print(f'Hard for findminhs: {len(hard_instances_findminhs)}')\n",
    "print(f'Hard & finished findminhs: {num_hard_finished_findminhs}')\n",
    "print('Hard for gurobi: '\n",
    "      f'{len(all_instance_names) - len(easy_instances_gurobi)}')\n",
    "print(f'Hard & finished gurobi: {num_hard_finished_gurobi}')\n",
    "print()\n",
    "print('Hard only for findminhs: '\n",
    "      f'{len(easy_instances_gurobi - easy_instances_findminhs)}')\n",
    "print('Hard only for gurobi: '\n",
    "      f'{len(easy_instances_findminhs - easy_instances_gurobi)}')\n",
    "print()\n",
    "print('Finished only for findminhs: '\n",
    "      f'{len(unfinished_gurobi - unfinished_findminhs)}')\n",
    "print('Finished only for gurobi: '\n",
    "      f'{len(unfinished_findminhs - unfinished_gurobi)}')\n",
    "\n",
    "\n",
    "def get_df_hard_finished(name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a data frame for an experiment, containing only the instances\n",
    "    that were hard for the default setting and finished in this experiment.\n",
    "    \"\"\"\n",
    "    df = dfs_by_experiment[name]\n",
    "    return df[df.index.isin(hard_instances_findminhs)].dropna()\n",
    "\n",
    "\n",
    "def get_dfs_hard_finished(names: Iterable[str]) -> Dict[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns data frames for multiple experiments, containing only the\n",
    "    instances that were hard for the default setting and finished in\n",
    "    all of the given experiments.\n",
    "\n",
    "    A message is printed listing how many instances were removed since\n",
    "    they didn't finish in all of the given experiments.\n",
    "    \"\"\"\n",
    "    dfs = {name: get_df_hard_finished(name) for name in names}\n",
    "    indices = [df.index for df in dfs.values()]\n",
    "    index_intersection = reduce(lambda i1, i2: i1.intersection(i2), indices)\n",
    "    index_union = reduce(lambda i1, i2: i1.union(i2), indices)\n",
    "    dropped = set(index_union) - set(index_intersection)\n",
    "    if dropped:\n",
    "        print(\n",
    "            f'Dropping {len(dropped)} instances since they did not finish in '\n",
    "            'all experiments')\n",
    "        print(f'Dropped instances: {dropped}')\n",
    "    else:\n",
    "        print('No instances were dropped (all finished in all experiments)')\n",
    "    return {\n",
    "        name: df[df.index.isin(index_intersection)].copy()\n",
    "        for name, df in dfs.items()\n",
    "    }\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hard for findminhs: 142\n",
      "Hard & finished findminhs: 136\n",
      "Hard for gurobi: 300\n",
      "Hard & finished gurobi: 288\n",
      "\n",
      "Hard only for findminhs: 0\n",
      "Hard only for gurobi: 158\n",
      "\n",
      "Finished only for findminhs: 8\n",
      "Finished only for gurobi: 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df = dfs_by_experiment['default'].copy()\n",
    "df = df[df.runtimes__total.fillna(EXPERIMENT_TIMEOUT) >= 1]\n",
    "df = df.join(gurobi_reduced_df)\n",
    "df['runtime_gurobi'] = df.runtime\n",
    "df = df[df.runtime_gurobi.notna() | df.runtimes__total.notna()]\n",
    "df = df.fillna(EXPERIMENT_TIMEOUT)\n",
    "df['speedup'] = df.runtime_gurobi / df.runtimes__total\n",
    "df['slowdown'] = 1 / df.speedup\n",
    "\n",
    "is_random_instance = df.index.str.match(random_instance_regex)\n",
    "\n",
    "print(f'{df[is_random_instance & (df.runtime_gurobi >= 30 * 60)].speedup.min()=}')\n",
    "print(f'{df[is_random_instance & (df.runtime_gurobi < 30 * 60)].speedup.mean()=}')\n",
    "print(f'{np.mean([x - 1 if x > 1 else -(1/x - 1) for x in df[is_random_instance & (df.runtime_gurobi < 30 * 60)].speedup])=}')\n",
    "\n",
    "print(f'{len(df[df.speedup > 1])=}')\n",
    "print(f'{len(df[df.speedup < 1])=}')\n",
    "\n",
    "print(f'{len(df[~is_random_instance & (df.speedup > 1)])=}')\n",
    "print(f'{len(df[~is_random_instance & (df.speedup < 1)])=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "df[is_random_instance & (df.runtime_gurobi >= 30 * 60)].speedup.min()=1.3440892894899874\n",
      "df[is_random_instance & (df.runtime_gurobi < 30 * 60)].speedup.mean()=0.8999855183603095\n",
      "np.mean([x - 1 if x > 1 else -(1/x - 1) for x in df[is_random_instance & (df.runtime_gurobi < 30 * 60)].speedup])=-0.5700824057200232\n",
      "len(df[df.speedup > 1])=95\n",
      "len(df[df.speedup < 1])=43\n",
      "len(df[~is_random_instance & (df.speedup > 1)])=68\n",
      "len(df[~is_random_instance & (df.speedup < 1)])=12\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df = dfs_by_experiment['default'].copy()\n",
    "df = df.join(gurobi_reduced_df.runtime.rename('runtime_gurobi'))\n",
    "df = df.fillna(EXPERIMENT_TIMEOUT)\n",
    "df['speedup'] = df.runtime_gurobi / df.runtimes__total\n",
    "\n",
    "is_random_instance = df.index.str.match(random_instance_regex)\n",
    "\n",
    "print(f'{len(df[(df.runtimes__total > 0.01) & (df.speedup > 1)])=}')\n",
    "print(f'{len(df[(df.runtimes__total > 0.01) & (df.speedup < 1)])=}')\n",
    "\n",
    "print(f'{len(df[~is_random_instance & (df.runtimes__total > 0.01) & (df.speedup > 1)])=}')\n",
    "print(f'{len(df[~is_random_instance & (df.runtimes__total > 0.01) & (df.speedup < 1)])=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(df[(df.runtimes__total > 0.01) & (df.speedup > 1)])=332\n",
      "len(df[(df.runtimes__total > 0.01) & (df.speedup < 1)])=56\n",
      "len(df[~is_random_instance & (df.runtimes__total > 0.01) & (df.speedup > 1)])=297\n",
      "len(df[~is_random_instance & (df.runtimes__total > 0.01) & (df.speedup < 1)])=24\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting general"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "WIDTH_1COL = 3.335\n",
    "WIDTH_2COL = 6.808\n",
    "\n",
    "\n",
    "# Settings for separating random and non-random instances\n",
    "class RndSettings(namedtuple('RndSettings', ['label', 'color', 'marker'])):\n",
    "    @property\n",
    "    def as_scatter(self) -> dict:\n",
    "        return {'c': self.color, 'label': self.label, 'marker': self.marker}\n",
    "\n",
    "\n",
    "RND_NONRND_SETTINGS = {\n",
    "    False: RndSettings(r'\\texttt{appl}', 'C0', 'o'),\n",
    "    True: RndSettings(r'\\texttt{rnd}', 'C1', 's'),\n",
    "}\n",
    "\n",
    "# Three different styles, by level of highlighting\n",
    "BACKGROUND_LINE_SETTINGS = [{\n",
    "    'color': 'black',\n",
    "    'linewidth': 0.75,\n",
    "    'zorder': -1,\n",
    "}, {\n",
    "    'color': 'gray',\n",
    "    'linewidth': 0.75,\n",
    "    'zorder': -1,\n",
    "}, {\n",
    "    'color': 'gray',\n",
    "    'linewidth': 0.5,\n",
    "    'zorder': -1,\n",
    "    'linestyle': (0, (5, 10)),\n",
    "}]\n",
    "\n",
    "mpl.rc('font', family='serif', serif='Computer Modern')\n",
    "mpl.rc('text', usetex=True)\n",
    "plt.rcParams.update({\n",
    "    'text.latex.preamble': r'''\n",
    "        \\usepackage{amsmath}\n",
    "        \\usepackage{xfrac}\n",
    "    ''',\n",
    "    'legend.fontsize': 'small',\n",
    "})\n",
    "plt.style.use('seaborn-colorblind')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "random_instance_regex = re.compile(r'p\\d+_\\d+\\.dat')\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def make_plot(\n",
    "    name: str, figsize: Tuple[int, int], **subplot_args\n",
    ") -> Iterable[Tuple[plt.Figure, Union[plt.Axes, np.ndarray[plt.Axes]]]]:\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots(**subplot_args)\n",
    "    yield fig, ax\n",
    "    fig.tight_layout()\n",
    "    Path('plots').mkdir(exist_ok=True)\n",
    "    fig.savefig(f'plots/{name}.pdf')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def root_lower_bounds(df: pd.DataFrame) -> pd.Series:\n",
    "    lower_bound_names = [\n",
    "        'max_degree', 'sum_degree', 'efficiency', 'packing', 'sum_over_packing'\n",
    "    ]\n",
    "    return reduce(np.maximum,\n",
    "                  (df[f'root_bounds__{name}'] for name in lower_bound_names))\n",
    "\n",
    "\n",
    "def rnd_and_nonrnd(\n",
    "        index: pd.Index) -> Iterable[Tuple[np.ndarray, RndSettings]]:\n",
    "    is_random_instance = index.str.match(random_instance_regex)\n",
    "    yield ~is_random_instance, RND_NONRND_SETTINGS[False]\n",
    "    yield is_random_instance, RND_NONRND_SETTINGS[True]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scatter plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def scatter_settings(hollow: bool = False) -> dict:\n",
    "    settings = {\n",
    "        # Roughly account for size increase when keeping outlines\n",
    "        's': (14 if hollow else 20),\n",
    "        'alpha': 0.7\n",
    "    }\n",
    "    if not hollow:\n",
    "        settings['linewidths'] = 0\n",
    "    return settings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Runtime comparison with Gurobi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def runtime_vs_runtime_plot(name: str, df: pd.DataFrame, xcol: str, ycol: str,\n",
    "                            xlabel: str, ylabel: str) -> None:\n",
    "    # Gurobis log entries only have two digits of precision.\n",
    "    # Therefore (and since the low values are not that interesting anyways)\n",
    "    # clip all values below 0.01 to 0.01.\n",
    "    x = df[xcol].fillna(EXPERIMENT_TIMEOUT).clip(lower=0.01)\n",
    "    y = df[ycol].fillna(EXPERIMENT_TIMEOUT).clip(lower=0.01)\n",
    "\n",
    "    with make_plot(name, (WIDTH_1COL, WIDTH_1COL)) as (_, ax):\n",
    "        is_timeout = df[xcol].isna() | df[ycol].isna()\n",
    "        for rnd_filt, settings in rnd_and_nonrnd(df.index):\n",
    "            for tle in [False, True]:\n",
    "                filt = rnd_filt & (is_timeout if tle else ~is_timeout)\n",
    "                label = settings.label\n",
    "                if tle:\n",
    "                    label += ' (timeout)'\n",
    "                ax.scatter(x[filt],\n",
    "                           y[filt],\n",
    "                           label=label,\n",
    "                           facecolors=('none' if tle else settings.color),\n",
    "                           edgecolors=settings.color,\n",
    "                           marker=settings.marker,\n",
    "                           **scatter_settings(hollow=tle))\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        mn = 0.01\n",
    "        mx = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "        ax.set_xlim((mn, mx))\n",
    "        ax.set_ylim((mn, mx))\n",
    "\n",
    "        ax.yaxis.set_major_locator(ax.xaxis.get_major_locator())\n",
    "        ax.yaxis.set_minor_locator(ax.xaxis.get_minor_locator())\n",
    "\n",
    "        ax.axline((mn, mn), (mx, mx), **BACKGROUND_LINE_SETTINGS[0])\n",
    "        for i in range(1, 10):\n",
    "            ax.axline((mn, mn * 10**i), (mx, mx * 10**i),\n",
    "                      **BACKGROUND_LINE_SETTINGS[2])\n",
    "            ax.axline((mn * 10**i, mn), (mx * 10**i, mx),\n",
    "                      **BACKGROUND_LINE_SETTINGS[2])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "\n",
    "df = dfs_by_experiment['default'].copy()\n",
    "runtime_vs_runtime_plot('runtime-vs-gurobi',\n",
    "                        df.join(gurobi_df.rename('runtime_gurobi')),\n",
    "                        'runtime_gurobi', 'runtimes__total',\n",
    "                        'Runtime Gurobi (s)', 'Runtime (s)')\n",
    "\n",
    "runtime_vs_runtime_plot(\n",
    "    'runtime-vs-gurobi-reduced',\n",
    "    df.join(gurobi_reduced_df.runtime.rename('runtime_gurobi')),\n",
    "    'runtime_gurobi', 'runtimes__total', 'Runtime Gurobi reduced (s)',\n",
    "    'Runtime (s)')\n",
    "\n",
    "df_gurobi = gurobi_reduced_df.join(gurobi_df.rename('runtime'),\n",
    "                                   lsuffix='_reduced')\n",
    "runtime_vs_runtime_plot('gurobi-vs-gurobi-reduced', df_gurobi, 'runtime',\n",
    "                        'runtime_reduced', 'Runtime Gurobi (s)',\n",
    "                        'Runtime Gurobi reduced (s)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search space by bound"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "lower = root_lower_bounds(df)\n",
    "gap = df.root_bounds__greedy_upper - lower\n",
    "\n",
    "with make_plot('search-space-bound-gap', (WIDTH_1COL, WIDTH_1COL)) as (_, ax):\n",
    "    for filt, settings in rnd_and_nonrnd(df.index):\n",
    "        ax.scatter(gap[filt], df[filt].branching_steps, **settings.as_scatter,\n",
    "                   **scatter_settings())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_yscale('symlog')\n",
    "\n",
    "    ax.set_xlabel(r'Bound gap ($\\text{upper} - \\text{lower}$)')\n",
    "    ax.set_ylabel(r'Search space (\\#branching steps)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search space by instance size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "sizes = df.index.map(instance_size)\n",
    "\n",
    "with make_plot('search-space-instance-size',\n",
    "               (WIDTH_1COL, WIDTH_1COL)) as (_, ax):\n",
    "    for filt, settings in rnd_and_nonrnd(df.index):\n",
    "        ax.scatter(sizes[filt], df[filt].branching_steps,\n",
    "                   **settings.as_scatter, **scatter_settings())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_yscale('symlog')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax.set_xlabel(r'$\\lVert \\mathcal{F} \\rVert$')\n",
    "    ax.set_ylabel(r'Search space (\\#branching steps)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search space (combined plot)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "lower = root_lower_bounds(df)\n",
    "gap = df.root_bounds__greedy_upper - lower\n",
    "sizes = df.index.map(instance_size)\n",
    "\n",
    "with make_plot('search-space-combined', (WIDTH_2COL, WIDTH_1COL), nrows=1, ncols=2, sharey=True) as (fig, (ax0, ax1)):\n",
    "    for filt, settings in rnd_and_nonrnd(df.index):\n",
    "        ax0.scatter(sizes[filt], df[filt].branching_steps,\n",
    "                   **settings.as_scatter, **scatter_settings())\n",
    "    ax0.legend()\n",
    "    ax0.set_xscale('log')\n",
    "    ax0.set_yscale('symlog')\n",
    "    ax0.set_xlabel(r'$\\lVert \\mathcal{F} \\rVert$')\n",
    "    ax0.set_ylabel(r'Search space (\\#branching steps)')\n",
    "\n",
    "    for filt, settings in rnd_and_nonrnd(df.index):\n",
    "        ax1.scatter(gap[filt], df[filt].branching_steps, **settings.as_scatter,\n",
    "                   **scatter_settings())\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel(r'Bound gap ($\\text{upper} - \\text{lower}$)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bound gaps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "\n",
    "lower = root_lower_bounds(df)\n",
    "opt = df.opt\n",
    "upper = df.root_bounds__greedy_upper\n",
    "\n",
    "x = opt / lower\n",
    "y = upper / opt\n",
    "\n",
    "with make_plot('bound-gaps', (WIDTH_1COL, 1.6)) as (fig, ax):\n",
    "    for filt, settings in rnd_and_nonrnd(x.index):\n",
    "        ax.scatter(x[filt], y[filt], **settings.as_scatter,\n",
    "                   **scatter_settings())\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.xaxis.set_major_locator(ax.yaxis.get_major_locator())\n",
    "\n",
    "    ax.set_xlabel(r'$\\sfrac{\\text{opt}}{\\text{lower}}$')\n",
    "    ax.set_ylabel(r'$\\sfrac{\\text{upper}}{\\text{opt}}$')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Greedy modes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "names = [\n",
    "    'default', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "df = dfs['default']\n",
    "always_early_df = dfs['greedy-always-before-bounds']\n",
    "always_late_df = dfs['greedy-always-before-expensive-reductions']\n",
    "\n",
    "x = always_late_df.runtimes__total / df.runtimes__total\n",
    "y = always_early_df.runtimes__total / df.runtimes__total\n",
    "mx = round(1.1 * max(x.max(), y.max()), ndigits=1)\n",
    "\n",
    "with make_plot('where-greedy', (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "    for filt, settings in rnd_and_nonrnd(x.index):\n",
    "        ax.scatter(x[filt], y[filt], **settings.as_scatter,\n",
    "                   **scatter_settings())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Every loop, before expensive reductions')\n",
    "    ax.set_ylabel('Every loop, before bounds')\n",
    "    ax.set_xlim((0, mx))\n",
    "    ax.set_ylim((0, mx))\n",
    "\n",
    "    for p1, p2 in [((0, 1), (mx, 1)), ((1, 0), (1, mx)), ((0, 0), (mx, mx))]:\n",
    "        ax.axline(p1, p2, **BACKGROUND_LINE_SETTINGS[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Box plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Fill boxes in white by default so that background lines don't\n",
    "# appear to go through the boxes\n",
    "def boxplot_settings(facecolor: str = 'white') -> dict:\n",
    "    return {\n",
    "        'patch_artist': True,\n",
    "        'boxprops': {\n",
    "            'facecolor': facecolor,\n",
    "        },\n",
    "        'medianprops': {\n",
    "            'color': 'C4'\n",
    "        },\n",
    "        'flierprops': {\n",
    "            'marker': '.',\n",
    "            'markerfacecolor': 'black',\n",
    "            'markersize': 4,\n",
    "        },\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def boxplot_rnd_split(ax: pd.Axes,\n",
    "                      data: list[pd.Series],\n",
    "                      legend_props: Optional[dict] = None) -> None:\n",
    "    pos = np.arange(len(data)) + 1\n",
    "    width = 0.2\n",
    "    offset = 0.175\n",
    "\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    for i, (filt, settings) in enumerate(rnd_and_nonrnd(data[0].index)):\n",
    "        data_filt = [col[filt] for col in data]\n",
    "        bp = ax.boxplot(data_filt,\n",
    "                        widths=width,\n",
    "                        positions=pos + (offset if i else -offset),\n",
    "                        **boxplot_settings(settings.color))\n",
    "        legend_handles.append(bp['boxes'][0])\n",
    "        legend_labels.append(settings.label)\n",
    "\n",
    "    ax.legend(legend_handles, legend_labels, **(legend_props or {}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Operation runtimes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "parts = {\n",
    "    'greedy': 'Greedy',\n",
    "    'max_degree_bound': 'Max\\ndeg.\\nbound',\n",
    "    'efficiency_bound': 'Eff.\\nbound',\n",
    "    'packing_bound': 'Packing\\nbound',\n",
    "    'sum_over_packing_bound': 'Sum\\nover\\npacking\\nbound',\n",
    "    'forced_vertex': 'Unit\\nedge',\n",
    "    'costly_discard_packing_update': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch': 'Costly\\ndiscard\\nrepack',\n",
    "    'vertex_domination': 'Vertex\\ndom.',\n",
    "    'edge_domination': 'Edge\\ndom.',\n",
    "    'other': 'Other',\n",
    "}\n",
    "df = get_df_hard_finished('default')\n",
    "\n",
    "non_other_runtimes = sum(\n",
    "    df[col] for col in df.columns\n",
    "    if col.startswith('runtimes__') and col not in (\n",
    "        'runtimes__total', 'runtimes__applying_reductions'))\n",
    "runtime_other = df.runtimes__total - non_other_runtimes\n",
    "\n",
    "data = [(runtime_other if col == 'other' else df[f'runtimes__{col}']) /\n",
    "        df.runtimes__total for col in parts.keys()]\n",
    "\n",
    "with make_plot('operations', (WIDTH_2COL, 2.5)) as (_, ax):\n",
    "    boxplot_rnd_split(ax,\n",
    "                      data,\n",
    "                      legend_props={\n",
    "                          'loc': 'upper left',\n",
    "                          'bbox_to_anchor': (0.08, 0, 1, 1)\n",
    "                      })\n",
    "\n",
    "    font_settings = dict(fontsize='x-small')\n",
    "    ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "    ax.set_xticks(np.arange(len(parts)) + 1)\n",
    "    ax.set_xticklabels(parts.values(), fontdict=font_settings)\n",
    "    ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels(ticklabels, fontdict=font_settings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search space by lower bound"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "bounds = {\n",
    "    'Max degree': 'max-degree-only',\n",
    "    'Sum degree': 'sum-degree-only',\n",
    "    'Efficiency': 'efficiency-only',\n",
    "    'Packing': 'packing-only',\n",
    "    'Packing\\n(local search)': 'packing-local-search-only',\n",
    "    'Sum\\nover packing': 'sum-over-packing-only',\n",
    "    'Sum\\nover packing\\n(local search)': 'packing-local-search-only',\n",
    "}\n",
    "dfs = get_dfs_hard_finished(list(bounds.values()) + ['default'])\n",
    "df = dfs['default']\n",
    "\n",
    "idx_nonzero = df[df.branching_steps > 0].index\n",
    "num_dropped = len(df) - len(idx_nonzero)\n",
    "print(f'Dropping {num_dropped} instances since they didnt branch when '\n",
    "      'using default settings')\n",
    "dfs = {name: df[df.index.isin(idx_nonzero)] for name, df in dfs.items()}\n",
    "df = dfs['default']\n",
    "print(f'Remaining: {len(df)} instances')\n",
    "\n",
    "data = [\n",
    "    dfs[name].branching_steps / df.branching_steps for name in bounds.values()\n",
    "]\n",
    "\n",
    "with make_plot('search-space-by-bound', (WIDTH_2COL, 2.1)) as (_, ax):\n",
    "    boxplot_rnd_split(ax,\n",
    "                      data,\n",
    "                      legend_props={\n",
    "                          'loc': 'upper left',\n",
    "                          'bbox_to_anchor': (0.73, 0, 0.8, 1)\n",
    "                      })\n",
    "\n",
    "    ax.set_yscale('symlog')\n",
    "    ax.set_xticks(np.arange(len(bounds)) + 1)\n",
    "    ax.set_xticklabels(bounds.keys())\n",
    "    ax.set_ylabel('Relative search space')\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 3 instances since they did not finish in all experiments\n",
      "Dropped instances: {'isolet_r7798_c618_r7798_c200_diff_sets.hg.dat', 'cost_matrix_component_nr_52_size_885_cutoff_10.0.cm.dat', 'p7_256000.dat'}\n",
      "Dropping 12 instances since they didnt branch when using default settings\n",
      "Remaining: 121 instances\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bound effectiveness"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "cols = [\n",
    "    'reductions__max_degree_bound_breaks',\n",
    "    'reductions__efficiency_degree_bound_breaks',\n",
    "    'reductions__packing_bound_breaks',\n",
    "    'reductions__sum_over_packing_bound_breaks',\n",
    "]\n",
    "df = get_df_hard_finished('default')\n",
    "total = sum(df[col] for col in cols)\n",
    "\n",
    "idx_nonzero = total[total != 0].index\n",
    "print(\n",
    "    f'Discarding {len(total) - len(idx_nonzero)} instances which didnt have any bound breaks'\n",
    ")\n",
    "df = df.reindex(idx_nonzero)\n",
    "total = total.reindex(idx_nonzero)\n",
    "\n",
    "data = [df[col] / total for col in cols]\n",
    "labels = ['Max\\ndegree', 'Efficiency', 'Packing', 'Sum over\\npacking']\n",
    "\n",
    "with make_plot('bound-comparison', (WIDTH_1COL, 2)) as (_, ax):\n",
    "    boxplot_rnd_split(ax, data)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)) + 1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "    ax.set_yticklabels(ticklabels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discarding 2 instances which didnt have any bound breaks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduction effectiveness"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "len_before = len(df)\n",
    "df = df[df.reductions__forced_vertex_runs > 0]\n",
    "print(\n",
    "    f'Discarding {len_before - len(df)} instances that never used reductions')\n",
    "\n",
    "times_reductions_reached = df.reductions__forced_vertex_runs\n",
    "later_reductions = {\n",
    "    'costly_discard_efficiency_runs': 'Costly\\ndiscard\\nefficiency',\n",
    "    'costly_discard_packing_update_runs': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch_runs': 'Costly\\ndiscard\\nrepack',\n",
    "    'vertex_dominations_runs': 'Vertex\\ndom.',\n",
    "    'edge_dominations_runs': 'Edge\\ndom.',\n",
    "}\n",
    "data = [\n",
    "    df[f'reductions__{col}'] / times_reductions_reached\n",
    "    for col in later_reductions.keys()\n",
    "]\n",
    "\n",
    "with make_plot('reduction-runs', (WIDTH_1COL, 2.5)) as (_, ax):\n",
    "    boxplot_rnd_split(ax, data)\n",
    "\n",
    "    ax.tick_params('both', labelsize='x-small')\n",
    "    ax.set_xticks(np.arange(len(later_reductions)) + 1)\n",
    "    ax.set_xticklabels(later_reductions.values())\n",
    "    ax.yaxis.set_major_formatter(plticker.PercentFormatter(xmax=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discarding 9 instances that never used reductions\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forced vertex effectiveness"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "df['reductions__costly_discard_packing_from_scratch_vertices_found'] = df.reductions__costly_discard_packing_from_scratch_steps_per_run.map(\n",
    "    lambda l: sum(l[:-1]))\n",
    "\n",
    "reductions = {\n",
    "    'forced': 'Unit\\nedge',\n",
    "    'costly_discard_efficiency': 'Costly\\ndiscard\\nefficiency',\n",
    "    'costly_discard_packing_update': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch': 'Costly\\ndiscard\\nrepack',\n",
    "}\n",
    "reductions = {\n",
    "    f'reductions__{col}_vertices_found': label\n",
    "    for col, label in reductions.items()\n",
    "}\n",
    "df['reductions__total_vertices_found'] = sum(df[col]\n",
    "                                             for col in reductions.keys())\n",
    "\n",
    "len_before = len(df)\n",
    "df = df[df['reductions__total_vertices_found'] > 0]\n",
    "print(\n",
    "    f'Removed {len_before - len(df)} instances for which no forced vertices were found'\n",
    ")\n",
    "\n",
    "data = [\n",
    "    df[col] / df.reductions__total_vertices_found for col in reductions.keys()\n",
    "]\n",
    "\n",
    "with make_plot('forced-vertices', (WIDTH_1COL, 2.5)) as (_, ax):\n",
    "    boxplot_rnd_split(ax, data)\n",
    "\n",
    "    ax.tick_params('both', labelsize='x-small')\n",
    "    ax.set_xticks(np.arange(len(data)) + 1)\n",
    "    ax.set_xticklabels(reductions.values())\n",
    "    ax.yaxis.set_major_formatter(plticker.PercentFormatter(xmax=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed 10 instances for which no forced vertices were found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## From scratch packing parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "names = [f'from-scratch-{i}' for i in [0] + list(range(1, 20, 2)) if i != 3]\n",
    "names.append('default')\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['from-scratch-0']\n",
    "num_dfs = {\n",
    "    num: dfs['default' if num == 3 else f'from-scratch-{num}']\n",
    "    for num in range(1, 20, 2)\n",
    "}\n",
    "\n",
    "data = [\n",
    "    df.runtimes__total / base_df.runtimes__total for df in num_dfs.values()\n",
    "]\n",
    "\n",
    "with make_plot('from-scratch', (WIDTH_2COL, 2.5)) as (_, ax):\n",
    "    boxplot_rnd_split(ax, data)\n",
    "\n",
    "    ax.set_xlabel(r'\\#Nodes checked')\n",
    "    ax.set_ylabel('Runtime (rel. to w/o rule)')\n",
    "    ax.set_xticks(range(1, len(num_dfs) + 1))\n",
    "    ax.set_xticklabels([str(num) for num in num_dfs.keys()])\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Greedy modes vs disabled"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "names = [\n",
    "    'default', 'greedy-never', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['greedy-never']\n",
    "data = [\n",
    "    dfs[name].runtimes__total / base_df.runtimes__total for name in [\n",
    "        'default',\n",
    "        'greedy-always-before-expensive-reductions',\n",
    "        'greedy-always-before-bounds',\n",
    "    ]\n",
    "]\n",
    "labels = [\n",
    "    'Once,\\nin the\\nbeginning', 'Every loop,\\nbefore expensive\\nreductions',\n",
    "    'Every loop,\\nbefore\\nbounds'\n",
    "]\n",
    "\n",
    "with make_plot('greedy-vs-off', (WIDTH_1COL, 2)) as (_, ax):\n",
    "    boxplot_rnd_split(ax, data, legend_props={'loc': 'lower right'})\n",
    "\n",
    "    ax.set_xlim(ax.get_xlim()[0], 1.1 * ax.get_xlim()[1])\n",
    "    ax.set_xticks(np.arange(len(labels)) + 1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.tick_params(axis='both', which='major', labelsize='x-small')\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Contour plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upper bound progress"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "\n",
    "\n",
    "def bound_improvement_curve(row) -> List[Tuple[float, float]]:\n",
    "    bound_gap = row.root_bounds__greedy_upper - row.opt\n",
    "    if bound_gap == 0:\n",
    "        return [(0, 1), (1, 1)]\n",
    "    curve = [(0, 0)]\n",
    "    for impr in row.upper_bound_improvements:\n",
    "        rel_time = impr[\"runtime\"] / row.runtimes__total\n",
    "        rel_bound = 1 - (impr[\"new_bound\"] - row.opt) / bound_gap\n",
    "        curve.append((rel_time, rel_bound))\n",
    "    return curve + [(1, 1)]\n",
    "\n",
    "\n",
    "df_full = get_df_hard_finished(\"default\")\n",
    "is_random_instance = df_full.index.str.match(random_instance_regex)\n",
    "settings = [('-rnd', is_random_instance), ('-nonrnd', ~is_random_instance),\n",
    "            ('-both', is_random_instance | ~is_random_instance)]\n",
    "\n",
    "for suffix, filt in settings:\n",
    "    df = df_full[filt].copy()\n",
    "\n",
    "    curves = [bound_improvement_curve(row) for row in df.itertuples()]\n",
    "    x = np.array(sorted({x for curve in curves for x, _y in curve}))\n",
    "\n",
    "    # Add slightly larger than 0 and slightly lower than 1 values, so that both 0 and 1\n",
    "    # are only used for the very edges of the plot\n",
    "    y = np.array(\n",
    "        sorted({y\n",
    "                for curve in curves for _x, y in curve} | {1e-12, 1 - 1e-12}))\n",
    "\n",
    "    z = np.zeros((len(x), len(y)))\n",
    "    rel = 1 / len(curves)\n",
    "    for curve in curves:\n",
    "        for i in range(len(curve)):\n",
    "            x_left, curve_y = curve[i]\n",
    "            x_right = 2 if i + 1 == len(curve) else curve[i + 1][0]\n",
    "            x_l = np.searchsorted(x, x_left, side=\"left\")\n",
    "            x_r = np.searchsorted(x, x_right, side=\"left\")\n",
    "            y_r = np.searchsorted(y, curve_y, side=\"right\")\n",
    "            z[x_l:x_r, :y_r] += rel\n",
    "\n",
    "    with make_plot(f'bound-updates{suffix}',\n",
    "                   (WIDTH_1COL, 0.85 * WIDTH_1COL)) as (fig, ax):\n",
    "        contour = ax.contourf(\n",
    "            x,\n",
    "            y,\n",
    "            z.transpose(),\n",
    "            cmap=\"Greys\",\n",
    "            levels=np.linspace(0, 1, 11),\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )\n",
    "\n",
    "        # For some reason, the black polygon bugged out and leaves some white part\n",
    "        # in the bottom right undrawn. This just lays a black background behind the\n",
    "        # contour plot.\n",
    "        ax.fill([0, 0, 1, 1], [0, 1, 1, 0], facecolor=\"black\", zorder=-1)\n",
    "\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlabel(\"Runtime\")\n",
    "        ax.set_ylabel(\"Upper bound progress\")\n",
    "\n",
    "        formatter = plticker.PercentFormatter(xmax=1)\n",
    "        ticks = np.linspace(0, 1, 6)\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.tick_params(\"both\", labelsize=\"x-small\")\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        cbar = fig.colorbar(contour,\n",
    "                            ticks=ticks,\n",
    "                            format=formatter,\n",
    "                            fraction=0.046,\n",
    "                            pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=\"x-small\")\n",
    "\n",
    "        # Matplotlib by default cuts of the y-label, this mostly fixes the issue\n",
    "        fig.subplots_adjust(left=-0.8)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edfe6049ab5675c7b9b2a1e09418e73100ac83442bc85973e9f2e271101b608a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('findminhs-q4Va14KR': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}