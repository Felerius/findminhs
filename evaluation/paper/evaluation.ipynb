{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import annotations\n",
    "import contextlib\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "INSTANCE_DIR = Path('./instances')\n",
    "TIMEOUT_SECS = 10\n",
    "MIN_HARD_SECS = 1\n",
    "\n",
    "WIDTH_1COL = 3.335\n",
    "WIDTH_2COL = 6.808\n",
    "\n",
    "SCATTER_SETTINGS = {\n",
    "    's': 20,\n",
    "    'alpha': 0.7,\n",
    "    'linewidths': 0,\n",
    "}\n",
    "BOXPLOT_SETTINGS = {\n",
    "    # Fill boxes in white so that background lines don't appear to go\n",
    "    # through the boxes\n",
    "    'patch_artist': True,\n",
    "    'boxprops': {\n",
    "        'facecolor': 'white',\n",
    "    }\n",
    "}\n",
    "BACKGROUND_LINE_SETTINGS = {\n",
    "    'color': 'gray',\n",
    "    'linewidth': 0.75,\n",
    "    'zorder': -1,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matplotlib config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mpl.rc('font', family='serif', serif='Computer Modern')\n",
    "mpl.rc('text', usetex=True)\n",
    "plt.rcParams.update({\n",
    "    'text.latex.preamble': r'''\n",
    "        \\usepackage{amsmath}\n",
    "    '''\n",
    "})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "result_dirs = [d for d in Path('results').glob('*') if d.is_dir()]\n",
    "for results_dir in tqdm(result_dirs):\n",
    "    data = [json.loads(f.read_text()) for f in results_dir.glob('**/*.json')]\n",
    "    with Path(f'results/{results_dir.name}.json').open('w') as f:\n",
    "        json.dump(data, f)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4effe0e4acb421aaf34382559c3653d"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "all_instance_names = [f.name for f in INSTANCE_DIR.glob('*.dat')]\n",
    "\n",
    "\n",
    "def fix_column_names(col):\n",
    "    if col.startswith('__'):\n",
    "        return col[2:]\n",
    "    return col\n",
    "\n",
    "\n",
    "def load_combined_json(path: Path) -> pd.DataFrame:\n",
    "    with path.open() as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.json_normalize(data, sep='__').rename(columns=fix_column_names)\n",
    "    df.set_index('file_name', inplace=True)\n",
    "    return df.reindex(all_instance_names)\n",
    "\n",
    "\n",
    "\n",
    "json_files = list(Path('results').glob('*.json'))\n",
    "dfs_by_experiment = {f.stem: load_combined_json(f) for f in tqdm(json_files)}"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "338f3ff654d940498a8011887af3772e"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Gurobi results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Gurobi log parsing\n",
    "GUROBI_REGEXES = [\n",
    "    re.compile(regex, re.MULTILINE) for regex in (\n",
    "        r'^Presolve time: (.*)s$',\n",
    "        r'^Root relaxation: .*?, .*? iterations, (.*?) seconds$',\n",
    "        r'^Explored .*? nodes \\(.*? simplex iterations\\) in (.*?) seconds$',\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def gurobi_parse_time(log_file: Path) -> Optional[float]:\n",
    "    text = Path(log_file).read_text()\n",
    "    matches = [regex.search(text) for regex in GUROBI_REGEXES]\n",
    "    # Solving finished if the last message matched by the last regex appears\n",
    "    if matches[-1] is None:\n",
    "        return None\n",
    "    return sum(float(m[1]) for m in matches if m is not None)\n",
    "\n",
    "\n",
    "gurobi_logs = list(Path('gurobi-logs').glob('*.log'))\n",
    "gurobi_runtimes = {(f.stem + '.dat'): gurobi_parse_time(f)\n",
    "                   for f in tqdm(gurobi_logs)}\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edb3e9dd27a743cebcc1a2ea0f126469"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting instance sizes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_instance_size(p: Path) -> int:\n",
    "    with p.open() as f:\n",
    "        # Skip initial line containing node and edge count\n",
    "        next(f)\n",
    "        return sum(int(line.split(maxsplit=1)[0]) for line in f)\n",
    "\n",
    "\n",
    "instances = list(INSTANCE_DIR.glob('*.dat'))\n",
    "instance_size = {f.name: get_instance_size(f) for f in tqdm(instances)}"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25d08f27a28b440a9d49ea5b078584ad"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying instances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Hard instance for solver: required >= MIN_HARD_SECS seconds to finish\n",
    "# Easy: not hard\n",
    "\n",
    "default_df = dfs_by_experiment['default']\n",
    "easy_instances_findminhs = set(\n",
    "    default_df[default_df.runtimes__total < MIN_HARD_SECS].index)\n",
    "easy_instances_gurobi = {\n",
    "    name\n",
    "    for name, runtime in gurobi_runtimes.items()\n",
    "    if runtime is not None and runtime < MIN_HARD_SECS\n",
    "}\n",
    "easy_instances_both = easy_instances_findminhs & easy_instances_gurobi\n",
    "hard_instances_findminhs = set(all_instance_names) - easy_instances_findminhs\n",
    "\n",
    "num_hard_finished_findminhs = len(\n",
    "    default_df[default_df.index.isin(hard_instances_findminhs)].dropna())\n",
    "num_hard_finished_gurobi = sum(1 for t in gurobi_runtimes.values()\n",
    "                               if t is not None and t >= MIN_HARD_SECS)\n",
    "unfinished_gurobi = {\n",
    "    name\n",
    "    for name, runtime in gurobi_runtimes.items() if runtime is None\n",
    "}\n",
    "unfinished_findminhs = set(default_df[default_df.runtimes__total.isna()].index)\n",
    "\n",
    "print(f'Hard for findminhs: {len(hard_instances_findminhs)}')\n",
    "print(f'Hard & finished findminhs: {num_hard_finished_findminhs}')\n",
    "print('Hard for gurobi: '\n",
    "      f'{len(all_instance_names) - len(easy_instances_gurobi)}')\n",
    "print(f'Hard & finished gurobi: {num_hard_finished_gurobi}')\n",
    "print()\n",
    "print('Hard only for findminhs: '\n",
    "      f'{len(easy_instances_gurobi - easy_instances_findminhs)}')\n",
    "print('Hard only for gurobi: '\n",
    "      f'{len(easy_instances_findminhs - easy_instances_gurobi)}')\n",
    "print()\n",
    "print('Finished only for findminhs: '\n",
    "      f'{len(unfinished_gurobi - unfinished_findminhs)}')\n",
    "print('Finished only for gurobi: '\n",
    "      f'{len(unfinished_findminhs - unfinished_gurobi)}')\n",
    "\n",
    "\n",
    "def get_df_hard_finished(name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a data frame for an experiment, containing only the instances\n",
    "    that were hard for the default setting and finished in this experiment.\n",
    "    \"\"\"\n",
    "    df = dfs_by_experiment[name]\n",
    "    return df[df.index.isin(hard_instances_findminhs)].dropna()\n",
    "\n",
    "\n",
    "def get_dfs_hard_finished(names: Iterable[str]) -> Dict[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns data frames for multiple experiments, containing only the\n",
    "    instances that were hard for the default setting and finished in\n",
    "    all of the given experiments.\n",
    "\n",
    "    A message is printed listing how many instances were removed since\n",
    "    they didn't finish in all of the given experiments.\n",
    "    \"\"\"\n",
    "    dfs = {name: get_df_hard_finished(name) for name in names}\n",
    "    indices = [df.index for df in dfs.values()]\n",
    "    index_intersection = reduce(lambda i1, i2: i1.intersection(i2), indices)\n",
    "    index_union = reduce(lambda i1, i2: i1.union(i2), indices)\n",
    "    dropped = set(index_union) - set(index_intersection)\n",
    "    print(f'Dropping {len(dropped)} instances since they did not finish in '\n",
    "          'all experiments')\n",
    "    print(f'Dropped instances: {dropped}')\n",
    "    return {\n",
    "        name: df[df.index.isin(index_intersection)].copy()\n",
    "        for name, df in dfs.items()\n",
    "    }\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hard for findminhs: 142\n",
      "Hard & finished findminhs: 48\n",
      "Hard for gurobi: 319\n",
      "Hard & finished gurobi: 290\n",
      "\n",
      "Hard only for findminhs: 0\n",
      "Hard only for gurobi: 177\n",
      "\n",
      "Finished only for findminhs: 0\n",
      "Finished only for gurobi: 65\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "@contextlib.contextmanager\n",
    "def make_plot(\n",
    "        name: str,\n",
    "        figsize: Tuple[int, int]) -> Iterable[Tuple[plt.Figure, plt.Axes]]:\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots()\n",
    "    yield fig, ax\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'plots/{name}.pdf')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def root_lower_bounds(df: pd.DataFrame) -> pd.Series:\n",
    "    lower_bound_names = [\n",
    "        'max_degree', 'sum_degree', 'efficiency', 'packing', 'sum_over_packing'\n",
    "    ]\n",
    "    return reduce(np.maximum,\n",
    "                  (df[f'root_bounds__{name}'] for name in lower_bound_names))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Runtime comparison with Gurobi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "df = dfs_by_experiment['default'].copy()\n",
    "df['runtimes__gurobi'] = df.index.map(gurobi_runtimes)\n",
    "\n",
    "# Remove all instances that don't finish for either\n",
    "df = df[df.runtimes__gurobi.notna() & df.runtimes__total.notna()]\n",
    "\n",
    "# Gurobis log entries only have two digits of precision.\n",
    "# Therefore (and since the low values are not that interesting anyways)\n",
    "# clip all values below 0.01 to 0.01.\n",
    "x = df.runtimes__gurobi.clip(lower=0.01)\n",
    "y = df.runtimes__total.clip(lower=0.01)\n",
    "\n",
    "# Round up/down to nearest power 10 plus margin\n",
    "mx_log = math.log10(max(x.max(), y.max()))\n",
    "mx = 10**max(math.ceil(mx_log), mx_log + 0.1)\n",
    "mn_log = math.log10(min(x.min(), y.min()))\n",
    "mn = 10**min(math.floor(mn_log), mn_log - 0.1)\n",
    "\n",
    "with make_plot('runtime-vs-gurobi', (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "    ax.scatter(x, y, **SCATTER_SETTINGS)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    mn = 0.01\n",
    "    mx = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "    ax.set_xlim((mn, mx))\n",
    "    ax.set_ylim((mn, mx))\n",
    "\n",
    "    ax.yaxis.set_major_locator(ax.xaxis.get_major_locator())\n",
    "    ax.yaxis.set_minor_locator(ax.xaxis.get_minor_locator())\n",
    "\n",
    "    ax.autoscale(enable=False)\n",
    "    ax.plot((mn, mx), (mn, mx), **BACKGROUND_LINE_SETTINGS)\n",
    "    for i in range(1, 100):\n",
    "        if mn * 10**i > mx:\n",
    "            break\n",
    "        ax.plot((mn * 10**i, mx), (mn, mx / 10**i),\n",
    "                **BACKGROUND_LINE_SETTINGS,\n",
    "                linestyle='dashed')\n",
    "        ax.plot((mn, mx / 10**i), (mn * 10**i, mx),\n",
    "                **BACKGROUND_LINE_SETTINGS,\n",
    "                linestyle='dashed')\n",
    "\n",
    "    ax.set_xlabel('Runtime Gurobi (s)')\n",
    "    ax.set_ylabel('Runtime (s)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "default_df = get_df_hard_finished('default')\n",
    "\n",
    "\n",
    "def search_space_plot(name: str,\n",
    "                      x,\n",
    "                      xlabel: str,\n",
    "                      xlog: bool = False) -> None:\n",
    "    with make_plot(name, (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "        y = default_df.branching_steps.dropna()\n",
    "        ax.scatter(x, default_df.branching_steps, **SCATTER_SETTINGS)\n",
    "        ax.set_yscale('symlog')\n",
    "        if xlog:\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(r'Search space (\\#branching steps)')\n",
    "\n",
    "\n",
    "lower = root_lower_bounds(default_df)\n",
    "gap = default_df.root_bounds__greedy_upper - lower\n",
    "search_space_plot('search-space-bound-gap', gap,\n",
    "                  r'Bound gap ($\\text{upper} - \\text{lower}$)')\n",
    "\n",
    "sizes = default_df.index.map(instance_size)\n",
    "search_space_plot('search-space-instance-size',\n",
    "                  sizes,\n",
    "                  r'$\\lVert \\mathcal{F} \\rVert$',\n",
    "                  xlog=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lower bound vs. opt vs. upper bound (for full instance)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "default_df = get_df_hard_finished('default')\n",
    "\n",
    "lower = root_lower_bounds(default_df);\n",
    "opt = default_df.opt\n",
    "upper = default_df.root_bounds__greedy_upper\n",
    "\n",
    "x = lower / opt\n",
    "y = upper / opt\n",
    "mx = round(1.1 * y.max(), ndigits = 1)\n",
    "x_mn = math.floor(10 * 0.95 * x.min()) / 10\n",
    "\n",
    "with make_plot('bound-gaps', (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "    ax.scatter(x, y, **SCATTER_SETTINGS)\n",
    "\n",
    "    ax.set_xlim((x_mn, 1.03))\n",
    "    ax.set_ylim((0.97, mx))\n",
    "    ax.xaxis.set_major_locator(plticker.MultipleLocator(base=0.2))\n",
    "    ax.yaxis.set_major_locator(plticker.MultipleLocator(base=0.5))\n",
    "\n",
    "    ax.set_xlabel('Lower bound (relative to opt)')\n",
    "    ax.set_ylabel('Upper bound (relative to opt)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Runtime comparison of different operations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "parts = {\n",
    "    'greedy': 'greedy',\n",
    "    'max_degree_bound': 'max\\ndeg.\\nbound',\n",
    "    'efficiency_bound': 'eff.\\nbound',\n",
    "    'packing_bound': 'packing\\nbound',\n",
    "    'sum_over_packing_bound': 'sum\\nover\\npacking\\nbound',\n",
    "    'forced_vertex': 'forced\\nvertex',\n",
    "    'costly_discard_packing_update': 'costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch': 'costly\\ndiscard\\nrepack',\n",
    "    'vertex_domination': 'vertex\\ndom.',\n",
    "    'edge_domination': 'edge\\ndom.',\n",
    "    'other': 'other',\n",
    "}\n",
    "df = get_df_hard_finished('default')\n",
    "\n",
    "non_other_runtimes = sum(\n",
    "    df[col] for col in default_df.columns\n",
    "    if col.startswith('runtimes__') and col not in (\n",
    "        'runtimes__total', 'runtimes__applying_reductions'))\n",
    "runtime_other = df.runtimes__total - non_other_runtimes\n",
    "\n",
    "data = [(runtime_other if col == 'other' else df[f'runtimes__{col}']) /\n",
    "        df.runtimes__total for col in parts.keys()]\n",
    "\n",
    "with make_plot('operations', (WIDTH_2COL, 2.5)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "    font_settings = dict(fontsize='x-small')\n",
    "    ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "    ax.set_xticklabels(parts.values(), fontdict=font_settings)\n",
    "    ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels(ticklabels, fontdict=font_settings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison of search space with different lower bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "bounds = {\n",
    "    'Max degree': 'max-degree-only',\n",
    "    'Sum degree': 'sum-degree-only',\n",
    "    'Efficiency': 'efficiency-only',\n",
    "    'Packing': 'packing-only',\n",
    "    'Packing\\n(local search)': 'packing-local-search-only',\n",
    "    'Sum\\nover packing': 'sum-over-packing-only',\n",
    "    'Sum\\nover packing\\n(local search)': 'packing-local-search-only',\n",
    "}\n",
    "dfs = get_dfs_hard_finished(list(bounds.values()) + ['default'])\n",
    "default_df = dfs['default']\n",
    "\n",
    "idx_nonzero = default_df[default_df.branching_steps > 0].index\n",
    "num_dropped = len(default_df) - len(idx_nonzero)\n",
    "print(f'Dropping {num_dropped} instances since they didnt branch when '\n",
    "      'using default settings')\n",
    "dfs = {name: df[df.index.isin(idx_nonzero)] for name, df in dfs.items()}\n",
    "default_df = dfs['default']\n",
    "print(f'Remaining: {len(default_df)} instances')\n",
    "\n",
    "data = [\n",
    "    dfs[name].branching_steps / default_df.branching_steps\n",
    "    for name in bounds.values()\n",
    "]\n",
    "\n",
    "with make_plot('search-space-by-bound', (WIDTH_2COL, 3)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xticklabels(bounds.keys())\n",
    "    ax.set_ylabel('Relative search space')\n",
    "\n",
    "    ax.autoscale(enable=False)\n",
    "    ax.plot(ax.get_xlim(), (1, 1), **BACKGROUND_LINE_SETTINGS, linestyle='dashed')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 1 instances since they did not finish in all experiments\n",
      "Dropped instances: {'isolet_r7798_c618_r7798_c200_diff_sets.hg.dat'}\n",
      "Dropping 10 instances since they didnt branch when using default settings\n",
      "Remaining: 37 instances\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How often are reductions applied? How often are they successfull?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "cols = [\n",
    "    'reductions__max_degree_bound_breaks',\n",
    "    'reductions__efficiency_degree_bound_breaks',\n",
    "    'reductions__packing_bound_breaks',\n",
    "    'reductions__sum_over_packing_bound_breaks',\n",
    "]\n",
    "default_df = get_df_hard_finished('default')\n",
    "total = sum(default_df[col] for col in cols)\n",
    "\n",
    "idx_nonzero = total[total != 0].index\n",
    "print(f'Discarding {len(total) - len(idx_nonzero)} instances which didnt have any bound breaks')\n",
    "default_df = default_df.reindex(idx_nonzero)\n",
    "total = total.reindex(idx_nonzero)\n",
    "\n",
    "data = [default_df[col] / total for col in cols]\n",
    "labels = ['Max\\ndegree', 'Efficiency', 'Packing', 'Sum over\\npacking']\n",
    "\n",
    "with make_plot('bound-comparison', (WIDTH_1COL, 2)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "    ax.set_yticklabels(ticklabels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discarding 1 instances which didnt have any bound breaks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How many vertices to check in the costly discard from scratch packing rule?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "names = [f'from-scratch-{i}' for i in [0] + list(range(1, 20, 2)) if i != 3]\n",
    "names.append('default')\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['from-scratch-0']\n",
    "num_dfs = {\n",
    "    num: dfs['default' if num == 3 else f'from-scratch-{num}']\n",
    "    for num in range(1, 20, 2)\n",
    "}\n",
    "\n",
    "data = [\n",
    "    df.runtimes__total / base_df.runtimes__total for df in num_dfs.values()\n",
    "]\n",
    "\n",
    "with make_plot('from-scratch', (WIDTH_2COL, 2.5)) as (fix, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "    ax.set_xlabel(r'\\#Nodes checked')\n",
    "    ax.set_ylabel('Runtime (rel. to w/o rule)')\n",
    "    ax.set_xticks(range(1, len(num_dfs) + 1))\n",
    "    ax.set_xticklabels([str(num) for num in num_dfs.keys()])\n",
    "\n",
    "    ax.autoscale(enable=False)\n",
    "    ax.plot(ax.get_xlim(), (1, 1),\n",
    "            **BACKGROUND_LINE_SETTINGS,\n",
    "            linestyle='dashed')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 0 instances since they did not finish in all experiments\n",
      "Dropped instances: set()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How often and when are better upper bounds found?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "\n",
    "\n",
    "def bound_improvement_curve(row) -> List[Tuple[float, float]]:\n",
    "    bound_gap = row.root_bounds__greedy_upper - row.opt\n",
    "    if bound_gap == 0:\n",
    "        return [(0, 1), (1, 1)]\n",
    "    curve = [(0, 0)]\n",
    "    for impr in row.upper_bound_improvements:\n",
    "        rel_time = impr['runtime'] / row.runtimes__total\n",
    "        rel_bound = 1 - (impr['new_bound'] - row.opt) / bound_gap\n",
    "        curve.append((rel_time, rel_bound))\n",
    "    return curve + [(1, 1)]\n",
    "\n",
    "\n",
    "NUM_SAMPLES = 500\n",
    "curves = [bound_improvement_curve(row) for row in df.itertuples()]\n",
    "x = np.linspace(0, 1, NUM_SAMPLES)\n",
    "y = np.linspace(0, 1, NUM_SAMPLES)\n",
    "\n",
    "# TODO: find a smart numpy way to do this\n",
    "z = np.zeros((NUM_SAMPLES, NUM_SAMPLES))\n",
    "rel = 1 / len(curves)\n",
    "for curve in curves:\n",
    "    x_idx = 0\n",
    "    for i in range(len(curve) - 1):\n",
    "        x_left, curve_y = curve[i]\n",
    "        x_right = curve[i + 1][0]\n",
    "        y_idx = np.searchsorted(y, curve_y, side='right')\n",
    "        while x_idx < NUM_SAMPLES and x[x_idx] <= x_right:\n",
    "            z[x_idx][:y_idx] += rel\n",
    "            x_idx += 1\n",
    "\n",
    "with make_plot('bound-updates', (WIDTH_1COL, 0.85 * WIDTH_1COL)) as (fig, ax):\n",
    "    contour = ax.contourf(x,\n",
    "                          y,\n",
    "                          z.transpose(),\n",
    "                          cmap='Greys',\n",
    "                          levels=np.linspace(0, 1, 11))\n",
    "\n",
    "    # For some reason, the black polygon bugged out and leaves some white part\n",
    "    # in the bottom right undrawn. This just lays a black background behind the\n",
    "    # contour plot.\n",
    "    ax.fill([0, 0, 1, 1], [0, 1, 1, 0], facecolor='black', zorder=-1)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('Runtime')\n",
    "    ax.set_ylabel('Upper bound progress')\n",
    "\n",
    "    formatter = plticker.PercentFormatter(xmax=1)\n",
    "    ticks = np.linspace(0, 1, 6)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.tick_params('both', labelsize='x-small')\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    cbar = fig.colorbar(contour,\n",
    "                        ticks=ticks,\n",
    "                        format=formatter,\n",
    "                        fraction=0.046,\n",
    "                        pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize='x-small')\n",
    "\n",
    "    # Matplotlib by default cuts of the y-label, this mostly fixes the issue\n",
    "    fig.subplots_adjust(left=-0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Is it worth doing upper bounds during the algo?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "names = [\n",
    "    'default', 'greedy-never', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['greedy-never']\n",
    "data = [\n",
    "    dfs[name].runtimes__total / base_df.runtimes__total for name in [\n",
    "        'default',\n",
    "        'greedy-always-before-expensive-reductions',\n",
    "        'greedy-always-before-bounds',\n",
    "    ]\n",
    "]\n",
    "labels = [\n",
    "    'Once,\\nin the\\nbeginning', 'Every loop,\\nbefore expensive\\nreductions',\n",
    "    'Every loop,\\nbefore\\nbounds'\n",
    "]\n",
    "\n",
    "with make_plot('greedy-vs-off', (WIDTH_1COL, 2)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.tick_params(axis='both', which='major', labelsize='x-small')\n",
    "    ax.yaxis.set_major_locator(plticker.MultipleLocator(base=0.5))\n",
    "\n",
    "    # This is very weird. Re-enabling autoscale shouldn't be necessary\n",
    "    # (and isn't in other boxplots). Anyway, this works (for now)...\n",
    "    xlim = ax.get_xlim()\n",
    "    ax.autoscale(enable=False)\n",
    "    ax.plot(ax.get_xlim(), (1, 1), **BACKGROUND_LINE_SETTINGS, linestyle='dashed')\n",
    "    ax.autoscale(enable=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 0 instances since they did not finish in all experiments\n",
      "Dropped instances: set()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where do we put greedy?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "names = [\n",
    "    'default', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "default_df = dfs['default']\n",
    "always_early_df = dfs['greedy-always-before-bounds']\n",
    "always_late_df = dfs['greedy-always-before-expensive-reductions']\n",
    "\n",
    "x = always_late_df.runtimes__total / default_df.runtimes__total\n",
    "y = always_early_df.runtimes__total / default_df.runtimes__total\n",
    "mx = round(1.1 * max(x.max(), y.max()), ndigits=1)\n",
    "\n",
    "with make_plot('where-greedy', (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "    ax.scatter(x, y, **SCATTER_SETTINGS)\n",
    "\n",
    "    ax.set_xlabel('Every loop, before expensive reductions')\n",
    "    ax.set_ylabel('Every loop, before bounds')\n",
    "    ax.set_xlim((0, mx))\n",
    "    ax.set_ylim((0, mx))\n",
    "\n",
    "    for xs, ys in [((0, mx), (1, 1)), ((1, 1), (0, mx)), ((0, mx), (0, mx))]:\n",
    "        ax.plot(xs, ys, **BACKGROUND_LINE_SETTINGS)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 0 instances since they did not finish in all experiments\n",
      "Dropped instances: set()\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edfe6049ab5675c7b9b2a1e09418e73100ac83442bc85973e9f2e271101b608a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('findminhs-q4Va14KR': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}