{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import annotations\n",
    "import contextlib\n",
    "import json\n",
    "import re\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "INSTANCE_DIR = Path('./instances')\n",
    "MIN_HARD_SECS = 1\n",
    "\n",
    "WIDTH_1COL = 3.335\n",
    "WIDTH_2COL = 6.808\n",
    "\n",
    "SCATTER_SETTINGS = {\n",
    "    's': 20,\n",
    "    'alpha': 0.7,\n",
    "    'linewidths': 0,\n",
    "}\n",
    "BOXPLOT_SETTINGS = {\n",
    "    # Fill boxes in white so that background lines don't appear to go\n",
    "    # through the boxes\n",
    "    'patch_artist': True,\n",
    "    'boxprops': {\n",
    "        'facecolor': 'white',\n",
    "    }\n",
    "}\n",
    "# Three different styles, by importance\n",
    "BACKGROUND_LINE_SETTINGS = [\n",
    "    {\n",
    "        'color': 'black',\n",
    "        'linewidth': 0.75,\n",
    "        'zorder': -1,\n",
    "    },\n",
    "    {\n",
    "        'color': 'gray',\n",
    "        'linewidth': 0.75,\n",
    "        'zorder': -1,\n",
    "    },\n",
    "    {\n",
    "        'color': 'gray',\n",
    "        'linewidth': 0.5,\n",
    "        'zorder': -1,\n",
    "        'linestyle': (0, (5, 10)),\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matplotlib config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mpl.rc('font', family='serif', serif='Computer Modern')\n",
    "mpl.rc('text', usetex=True)\n",
    "plt.rcParams.update({\n",
    "    'text.latex.preamble': r'''\n",
    "        \\usepackage{amsmath}\n",
    "        \\usepackage{xfrac}\n",
    "    '''\n",
    "})\n",
    "plt.style.use('seaborn-colorblind')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "result_dirs = [d for d in Path('results').glob('*') if d.is_dir()]\n",
    "for results_dir in tqdm(result_dirs, desc='Combining experiment json files'):\n",
    "    data = [json.loads(f.read_text()) for f in results_dir.glob('**/*.json')]\n",
    "    with Path(f'results/{results_dir.name}.json').open('w') as f:\n",
    "        json.dump(data, f)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Combining experiment json files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9adeda542c544fd9247a119cc310d6a"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "all_instance_names = [f.name for f in INSTANCE_DIR.glob('*.dat')]\n",
    "\n",
    "\n",
    "def fix_column_names(col):\n",
    "    if col.startswith('__'):\n",
    "        return col[2:]\n",
    "    return col\n",
    "\n",
    "\n",
    "def load_combined_json(path: Path) -> pd.DataFrame:\n",
    "    with path.open() as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.json_normalize(data, sep='__').rename(columns=fix_column_names)\n",
    "    df.set_index('file_name', inplace=True)\n",
    "    return df.reindex(all_instance_names)\n",
    "\n",
    "\n",
    "json_files = list(Path('results').glob('*.json'))\n",
    "dfs_by_experiment = {\n",
    "    f.stem: load_combined_json(f)\n",
    "    for f in tqdm(json_files, desc='Loading experiment data')\n",
    "}\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading experiment data:   0%|          | 0/21 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd0e338434524bdfb832716a95e159b9"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Gurobi results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Gurobi log parsing\n",
    "GUROBI_REGEXES = [\n",
    "    re.compile(regex, re.MULTILINE) for regex in (\n",
    "        r'^Presolve time: (.*)s$',\n",
    "        r'^Root relaxation: .*?, .*? iterations, (.*?) seconds$',\n",
    "        r'^Explored .*? nodes \\(.*? simplex iterations\\) in (.*?) seconds$',\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def gurobi_parse_time(log_file: Path) -> Optional[float]:\n",
    "    text = Path(log_file).read_text()\n",
    "    matches = [regex.search(text) for regex in GUROBI_REGEXES]\n",
    "    # Solving finished if the last message matched by the last regex appears\n",
    "    if matches[-1] is None:\n",
    "        return None\n",
    "    return sum(float(m[1]) for m in matches if m is not None)\n",
    "\n",
    "\n",
    "def load_gurobi_runtimes(directory: Path) -> pd.Series:\n",
    "    logs = list(directory.glob('*.log'))\n",
    "    runtimes = {(f.stem + '.dat'): gurobi_parse_time(f)\n",
    "                for f in tqdm(logs, desc='Analysing gurobi logs')}\n",
    "    series = pd.Series(runtimes, dtype=np.float64)\n",
    "    return series.reindex(all_instance_names)\n",
    "\n",
    "\n",
    "gurobi_df = load_gurobi_runtimes(Path('gurobi-logs'))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Analysing gurobi logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be09a477c23b429e9a8c5e84ca9a3354"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading reduced Gurobi results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def load_log(p: Path) -> dict:\n",
    "    with p.open() as f:\n",
    "        data = json.load(f)\n",
    "    data['file_name'] = p.with_suffix('.dat').name\n",
    "    return data\n",
    "\n",
    "\n",
    "reduction_logs = list(Path('reduction-logs').glob('*.json'))\n",
    "logs = [\n",
    "    load_log(p) for p in tqdm(reduction_logs, desc='Loading reduction logs')\n",
    "]\n",
    "gurobi_reduced_df = pd.DataFrame(logs)\n",
    "gurobi_reduced_df.set_index('file_name', inplace=True)\n",
    "gurobi_reduced_df = gurobi_reduced_df.reindex(all_instance_names)\n",
    "gurobi_reduced_df.runtime += load_gurobi_runtimes(Path('gurobi-reduced-logs'))\n",
    "\n",
    "vs_nonreduced = gurobi_reduced_df.runtime / gurobi_df\n",
    "vs_nonreduced = vs_nonreduced[vs_nonreduced.index.map(\n",
    "    lambda name: gurobi_df.loc[name] >= MIN_HARD_SECS)]\n",
    "improved = len(vs_nonreduced[vs_nonreduced < 0.5])\n",
    "deteriorated = len(vs_nonreduced[vs_nonreduced > 2.0])\n",
    "print(f'{improved} better by at least 2x, {deteriorated} worse by at least 2x')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading reduction logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afab7341b1ac48fca4f8ecd78ef3bee7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Analysing gurobi logs:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10e168406d6c4b96970259240dccb60b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46 better by at least 2x, 6 worse by at least 2x\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting instance sizes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_instance_size(p: Path) -> int:\n",
    "    with p.open() as f:\n",
    "        # Skip initial line containing node and edge count\n",
    "        next(f)\n",
    "        return sum(int(line.split(maxsplit=1)[0]) for line in f)\n",
    "\n",
    "\n",
    "instances = list(INSTANCE_DIR.glob('*.dat'))\n",
    "instance_size = {\n",
    "    f.name: get_instance_size(f)\n",
    "    for f in tqdm(instances, desc='Determining instances size')\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Determining instances size:   0%|          | 0/4256 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "730c5032e589496e852a58f74e9975e7"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying instances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Hard instance for solver: required >= MIN_HARD_SECS seconds to finish\n",
    "# Easy: not hard\n",
    "\n",
    "df = dfs_by_experiment['default']\n",
    "easy_instances_findminhs = set(df[df.runtimes__total < MIN_HARD_SECS].index)\n",
    "easy_instances_gurobi = set(gurobi_df[gurobi_df < MIN_HARD_SECS].index)\n",
    "easy_instances_both = easy_instances_findminhs & easy_instances_gurobi\n",
    "hard_instances_findminhs = set(all_instance_names) - easy_instances_findminhs\n",
    "\n",
    "num_hard_finished_findminhs = len(df[df.runtimes__total.notna()\n",
    "                                     & (df.runtimes__total >= MIN_HARD_SECS)])\n",
    "num_hard_finished_gurobi = len(gurobi_df[gurobi_df.notna()\n",
    "                                         & (gurobi_df >= MIN_HARD_SECS)])\n",
    "unfinished_findminhs = set(df[df.runtimes__total.isna()].index)\n",
    "unfinished_gurobi = set(gurobi_df[gurobi_df.isna()].index)\n",
    "\n",
    "print(f'Hard for findminhs: {len(hard_instances_findminhs)}')\n",
    "print(f'Hard & finished findminhs: {num_hard_finished_findminhs}')\n",
    "print('Hard for gurobi: '\n",
    "      f'{len(all_instance_names) - len(easy_instances_gurobi)}')\n",
    "print(f'Hard & finished gurobi: {num_hard_finished_gurobi}')\n",
    "print()\n",
    "print('Hard only for findminhs: '\n",
    "      f'{len(easy_instances_gurobi - easy_instances_findminhs)}')\n",
    "print('Hard only for gurobi: '\n",
    "      f'{len(easy_instances_findminhs - easy_instances_gurobi)}')\n",
    "print()\n",
    "print('Finished only for findminhs: '\n",
    "      f'{len(unfinished_gurobi - unfinished_findminhs)}')\n",
    "print('Finished only for gurobi: '\n",
    "      f'{len(unfinished_findminhs - unfinished_gurobi)}')\n",
    "\n",
    "\n",
    "def get_df_hard_finished(name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a data frame for an experiment, containing only the instances\n",
    "    that were hard for the default setting and finished in this experiment.\n",
    "    \"\"\"\n",
    "    df = dfs_by_experiment[name]\n",
    "    return df[df.index.isin(hard_instances_findminhs)].dropna()\n",
    "\n",
    "\n",
    "def get_dfs_hard_finished(names: Iterable[str]) -> Dict[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns data frames for multiple experiments, containing only the\n",
    "    instances that were hard for the default setting and finished in\n",
    "    all of the given experiments.\n",
    "\n",
    "    A message is printed listing how many instances were removed since\n",
    "    they didn't finish in all of the given experiments.\n",
    "    \"\"\"\n",
    "    dfs = {name: get_df_hard_finished(name) for name in names}\n",
    "    indices = [df.index for df in dfs.values()]\n",
    "    index_intersection = reduce(lambda i1, i2: i1.intersection(i2), indices)\n",
    "    index_union = reduce(lambda i1, i2: i1.union(i2), indices)\n",
    "    dropped = set(index_union) - set(index_intersection)\n",
    "    if dropped:\n",
    "        print(\n",
    "            f'Dropping {len(dropped)} instances since they did not finish in '\n",
    "            'all experiments')\n",
    "        print(f'Dropped instances: {dropped}')\n",
    "    else:\n",
    "        print('No instances were dropped (all finished in all experiments)')\n",
    "    return {\n",
    "        name: df[df.index.isin(index_intersection)].copy()\n",
    "        for name, df in dfs.items()\n",
    "    }\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hard for findminhs: 142\n",
      "Hard & finished findminhs: 136\n",
      "Hard for gurobi: 288\n",
      "Hard & finished gurobi: 275\n",
      "\n",
      "Hard only for findminhs: 0\n",
      "Hard only for gurobi: 146\n",
      "\n",
      "Finished only for findminhs: 9\n",
      "Finished only for gurobi: 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "@contextlib.contextmanager\n",
    "def make_plot(\n",
    "        name: str,\n",
    "        figsize: Tuple[int, int]) -> Iterable[Tuple[plt.Figure, plt.Axes]]:\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots()\n",
    "    yield fig, ax\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'plots/{name}.pdf')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def root_lower_bounds(df: pd.DataFrame) -> pd.Series:\n",
    "    lower_bound_names = [\n",
    "        'max_degree', 'sum_degree', 'efficiency', 'packing', 'sum_over_packing'\n",
    "    ]\n",
    "    return reduce(np.maximum,\n",
    "                  (df[f'root_bounds__{name}'] for name in lower_bound_names))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Runtime comparison with Gurobi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "def runtime_vs_runtime_plot(name: str, df: pd.DataFrame, xcol: str, ycol: str,\n",
    "                            xtimeout: int, ytimeout: int, xlabel: str,\n",
    "                            ylabel: str) -> None:\n",
    "    # Gurobis log entries only have two digits of precision.\n",
    "    # Therefore (and since the low values are not that interesting anyways)\n",
    "    # clip all values below 0.01 to 0.01.\n",
    "    x = df[xcol].fillna(xtimeout).clip(lower=0.01)\n",
    "    y = df[ycol].fillna(ytimeout).clip(lower=0.01)\n",
    "\n",
    "    with make_plot(name, (WIDTH_1COL, WIDTH_1COL)) as (_, ax):\n",
    "        for isna_x, isna_y, col, marker in [(False, False, 'C0', 'o'),\n",
    "                                            (False, True, 'C2', 's'),\n",
    "                                            (True, False, 'C1', 'D'),\n",
    "                                            (True, True, 'C3', 'X')]:\n",
    "            filt = (df[xcol].isna() == isna_x) & (df[ycol].isna() == isna_y)\n",
    "            ax.scatter(x[filt],\n",
    "                       y[filt],\n",
    "                       c=col,\n",
    "                       marker=marker,\n",
    "                       **SCATTER_SETTINGS)\n",
    "\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        mn = 0.01\n",
    "        mx = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "        ax.set_xlim((mn, mx))\n",
    "        ax.set_ylim((mn, mx))\n",
    "\n",
    "        ax.yaxis.set_major_locator(ax.xaxis.get_major_locator())\n",
    "        ax.yaxis.set_minor_locator(ax.xaxis.get_minor_locator())\n",
    "\n",
    "        ax.axline((mn, mn), (mx, mx), **BACKGROUND_LINE_SETTINGS[0])\n",
    "        for i in range(1, 10):\n",
    "            ax.axline((mn, mn * 10**i), (mx, mx * 10**i),\n",
    "                      **BACKGROUND_LINE_SETTINGS[2])\n",
    "            ax.axline((mn * 10**i, mn), (mx * 10**i, mx),\n",
    "                      **BACKGROUND_LINE_SETTINGS[2])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "\n",
    "df = dfs_by_experiment['default'].copy()\n",
    "runtime_vs_runtime_plot('runtime-vs-gurobi',\n",
    "                        df.join(gurobi_df.rename('runtime_gurobi')),\n",
    "                        'runtime_gurobi', 'runtimes__total', 24 * 60**2,\n",
    "                        24 * 60**2, 'Runtime Gurobi (s)', 'Runtime (s)')\n",
    "\n",
    "runtime_vs_runtime_plot(\n",
    "    'runtime-vs-gurobi-reduced',\n",
    "    df.join(gurobi_reduced_df.runtime.rename('runtime_gurobi')),\n",
    "    'runtime_gurobi', 'runtimes__total', 8 * 60**2, 24 * 60**2,\n",
    "    'Runtime Gurobi reduced (s)', 'Runtime (s)')\n",
    "\n",
    "df2 = gurobi_reduced_df.join(gurobi_df.rename('runtime'), lsuffix='_reduced')\n",
    "runtime_vs_runtime_plot('gurobi-vs-gurobi-reduced', df2, 'runtime',\n",
    "                        'runtime_reduced', 24 * 60**2, 8 * 60**2,\n",
    "                        'Runtime Gurobi (s)', 'Runtime Gurobi reduced (s)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "random_instance_regex = re.compile(r'p\\d+_\\d+\\.dat')\n",
    "\n",
    "\n",
    "def search_space_plot(name: str,\n",
    "                      x,\n",
    "                      xlabel: str,\n",
    "                      xlog: bool = False,\n",
    "                      separate_random: bool = False) -> None:\n",
    "    with make_plot(name, (WIDTH_1COL, WIDTH_1COL)) as (_, ax):\n",
    "        is_random_instance = df.index.to_series().str.match(\n",
    "            random_instance_regex)\n",
    "\n",
    "        ax.scatter(x[is_random_instance],\n",
    "                   df[is_random_instance].branching_steps,\n",
    "                   c=('C1' if separate_random else 'C0'),\n",
    "                   marker=('s' if separate_random else 'o'),\n",
    "                   label=r'\\texttt{EN1-random}',\n",
    "                   **SCATTER_SETTINGS)\n",
    "        ax.scatter(x[~is_random_instance],\n",
    "                   df[~is_random_instance].branching_steps,\n",
    "                   c='C0',\n",
    "                   label='Other',\n",
    "                   **SCATTER_SETTINGS)\n",
    "        if separate_random:\n",
    "            ax.legend()\n",
    "\n",
    "        ax.set_yscale('symlog')\n",
    "        if xlog:\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(r'Search space (\\#branching steps)')\n",
    "\n",
    "\n",
    "lower = root_lower_bounds(df)\n",
    "gap = df.root_bounds__greedy_upper - lower\n",
    "search_space_plot('search-space-bound-gap',\n",
    "                  gap,\n",
    "                  r'Bound gap ($\\text{upper} - \\text{lower}$)',\n",
    "                  separate_random=True)\n",
    "\n",
    "sizes = df.index.map(instance_size)\n",
    "search_space_plot('search-space-instance-size',\n",
    "                  sizes,\n",
    "                  r'$\\lVert \\mathcal{F} \\rVert$',\n",
    "                  xlog=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lower bound vs. opt vs. upper bound (for full instance)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "default_df = get_df_hard_finished('default')\n",
    "\n",
    "lower = root_lower_bounds(default_df);\n",
    "opt = default_df.opt\n",
    "upper = default_df.root_bounds__greedy_upper\n",
    "\n",
    "x = opt / lower\n",
    "y = upper / opt\n",
    "\n",
    "with make_plot('bound-gaps', (WIDTH_1COL, 1.6)) as (fig, ax):\n",
    "    ax.scatter(x, y, **SCATTER_SETTINGS)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.xaxis.set_major_locator(ax.yaxis.get_major_locator())\n",
    "\n",
    "    ax.set_xlabel(r'$\\sfrac{\\text{opt}}{\\text{lower}}$')\n",
    "    ax.set_ylabel(r'$\\sfrac{\\text{upper}}{\\text{opt}}$')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Runtime comparison of different operations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "parts = {\n",
    "    'greedy': 'Greedy',\n",
    "    'max_degree_bound': 'Max\\ndeg.\\nbound',\n",
    "    'efficiency_bound': 'Eff.\\nbound',\n",
    "    'packing_bound': 'Packing\\nbound',\n",
    "    'sum_over_packing_bound': 'Sum\\nover\\npacking\\nbound',\n",
    "    'forced_vertex': 'Unit\\nedge',\n",
    "    'costly_discard_packing_update': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch': 'Costly\\ndiscard\\nrepack',\n",
    "    'vertex_domination': 'Vertex\\ndom.',\n",
    "    'edge_domination': 'Edge\\ndom.',\n",
    "    'other': 'Other',\n",
    "}\n",
    "df = get_df_hard_finished('default')\n",
    "\n",
    "non_other_runtimes = sum(\n",
    "    df[col] for col in df.columns\n",
    "    if col.startswith('runtimes__') and col not in (\n",
    "        'runtimes__total', 'runtimes__applying_reductions'))\n",
    "runtime_other = df.runtimes__total - non_other_runtimes\n",
    "\n",
    "data = [(runtime_other if col == 'other' else df[f'runtimes__{col}']) /\n",
    "        df.runtimes__total for col in parts.keys()]\n",
    "\n",
    "for violin in (True, False):\n",
    "    suffix = '-violin' if violin else ''\n",
    "    with make_plot(f'operations{suffix}', (WIDTH_2COL, 2.5)) as (fig, ax):\n",
    "        if violin:\n",
    "            ax.violinplot(data)\n",
    "        else:\n",
    "            ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "        font_settings = dict(fontsize='x-small')\n",
    "        ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "        ax.set_xticks(np.arange(len(parts)) + 1)\n",
    "        ax.set_xticklabels(parts.values(), fontdict=font_settings)\n",
    "        ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        ax.set_yticklabels(ticklabels, fontdict=font_settings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison of search space with different lower bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "bounds = {\n",
    "    'Max degree': 'max-degree-only',\n",
    "    'Sum degree': 'sum-degree-only',\n",
    "    'Efficiency': 'efficiency-only',\n",
    "    'Packing': 'packing-only',\n",
    "    'Packing\\n(local search)': 'packing-local-search-only',\n",
    "    'Sum\\nover packing': 'sum-over-packing-only',\n",
    "    'Sum\\nover packing\\n(local search)': 'packing-local-search-only',\n",
    "}\n",
    "dfs = get_dfs_hard_finished(list(bounds.values()) + ['default'])\n",
    "default_df = dfs['default']\n",
    "\n",
    "idx_nonzero = default_df[default_df.branching_steps > 0].index\n",
    "num_dropped = len(default_df) - len(idx_nonzero)\n",
    "print(f'Dropping {num_dropped} instances since they didnt branch when '\n",
    "      'using default settings')\n",
    "dfs = {name: df[df.index.isin(idx_nonzero)] for name, df in dfs.items()}\n",
    "default_df = dfs['default']\n",
    "print(f'Remaining: {len(default_df)} instances')\n",
    "\n",
    "data = [\n",
    "    dfs[name].branching_steps / default_df.branching_steps\n",
    "    for name in bounds.values()\n",
    "]\n",
    "\n",
    "with make_plot('search-space-by-bound', (WIDTH_2COL, 3)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "    ax.set_yscale('symlog')\n",
    "    ax.set_xticks(np.arange(len(bounds)) + 1)\n",
    "    ax.set_xticklabels(bounds.keys())\n",
    "    ax.set_ylabel('Relative search space')\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropping 3 instances since they did not finish in all experiments\n",
      "Dropped instances: {'cost_matrix_component_nr_52_size_885_cutoff_10.0.cm.dat', 'isolet_r7798_c618_r7798_c200_diff_sets.hg.dat', 'p7_256000.dat'}\n",
      "Dropping 12 instances since they didnt branch when using default settings\n",
      "Remaining: 121 instances\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How often are reductions applied? How often are they successfull?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "cols = [\n",
    "    'reductions__max_degree_bound_breaks',\n",
    "    'reductions__efficiency_degree_bound_breaks',\n",
    "    'reductions__packing_bound_breaks',\n",
    "    'reductions__sum_over_packing_bound_breaks',\n",
    "]\n",
    "df = get_df_hard_finished('default')\n",
    "total = sum(default_df[col] for col in cols)\n",
    "\n",
    "idx_nonzero = total[total != 0].index\n",
    "print(\n",
    "    f'Discarding {len(total) - len(idx_nonzero)} instances which didnt have any bound breaks'\n",
    ")\n",
    "df = df.reindex(idx_nonzero)\n",
    "total = total.reindex(idx_nonzero)\n",
    "\n",
    "data = [df[col] / total for col in cols]\n",
    "labels = ['Max\\ndegree', 'Efficiency', 'Packing', 'Sum over\\npacking']\n",
    "\n",
    "for violin in (True, False):\n",
    "    suffix = '-violin' if violin else ''\n",
    "    with make_plot(f'bound-comparison{suffix}', (WIDTH_1COL, 2)) as (fig, ax):\n",
    "        ax.boxplot(data)\n",
    "        if violin:\n",
    "            ax.violinplot(data, showextrema=False, widths=0.45)\n",
    "\n",
    "        ax.set_xticks(np.arange(len(labels)) + 1)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        ticklabels = [fr'{num}\\%' for num in [0, 20, 40, 60, 80, 100]]\n",
    "        ax.set_yticklabels(ticklabels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discarding 2 instances which didnt have any bound breaks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reductions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "len_before = len(df)\n",
    "df = df[df.reductions__forced_vertex_runs > 0]\n",
    "print(\n",
    "    f'Discarding {len_before - len(df)} instances that never used reductions')\n",
    "\n",
    "times_reductions_reached = df.reductions__forced_vertex_runs\n",
    "later_reductions = {\n",
    "    'costly_discard_efficiency_runs': 'Costly\\ndiscard\\nefficiency',\n",
    "    'costly_discard_packing_update_runs': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch_runs': 'Costly\\ndiscard\\nrepack',\n",
    "    'vertex_dominations_runs': 'Vertex\\ndom.',\n",
    "    'edge_dominations_runs': 'Edge\\ndom.',\n",
    "}\n",
    "boxplot_data = [\n",
    "    df[f'reductions__{col}'] / times_reductions_reached\n",
    "    for col in later_reductions.keys()\n",
    "]\n",
    "\n",
    "with make_plot('reduction-runs', (WIDTH_1COL, 2.5)) as (fig, ax):\n",
    "    ax.boxplot(boxplot_data, **BOXPLOT_SETTINGS)\n",
    "    ax.tick_params('both', labelsize='x-small')\n",
    "    ax.set_xticks(np.arange(len(later_reductions)) + 1)\n",
    "    ax.set_xticklabels(later_reductions.values())\n",
    "    ax.yaxis.set_major_formatter(plticker.PercentFormatter(xmax=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discarding 9 instances that never used reductions\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forced vertices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "df = get_df_hard_finished('default')\n",
    "df['reductions__costly_discard_packing_from_scratch_vertices_found'] = df.reductions__costly_discard_packing_from_scratch_steps_per_run.map(\n",
    "    lambda l: sum(l[:-1]))\n",
    "\n",
    "reductions = {\n",
    "    'forced': 'Unit\\nedge',\n",
    "    'costly_discard_efficiency': 'Costly\\ndiscard\\nefficiency',\n",
    "    'costly_discard_packing_update': 'Costly\\ndiscard\\npacking\\nupdate',\n",
    "    'costly_discard_packing_from_scratch': 'Costly\\ndiscard\\nrepack',\n",
    "}\n",
    "reductions = {\n",
    "    f'reductions__{col}_vertices_found': label\n",
    "    for col, label in reductions.items()\n",
    "}\n",
    "df['reductions__total_vertices_found'] = sum(df[col]\n",
    "                                             for col in reductions.keys())\n",
    "\n",
    "len_before = len(df)\n",
    "df = df[df['reductions__total_vertices_found'] > 0]\n",
    "print(\n",
    "    f'Removed {len_before - len(df)} instances for which no forced vertices were found'\n",
    ")\n",
    "\n",
    "boxplot_data = [df[col] / df.reductions__total_vertices_found for col in reductions.keys()]\n",
    "\n",
    "with make_plot('forced-vertices', (WIDTH_1COL, 2.5)) as (fig, ax):\n",
    "    ax.boxplot(boxplot_data, **BOXPLOT_SETTINGS)\n",
    "    ax.tick_params('both', labelsize='x-small')\n",
    "    ax.set_xticklabels(reductions.values())\n",
    "    ax.yaxis.set_major_formatter(plticker.PercentFormatter(xmax=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed 10 instances for which no forced vertices were found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How many vertices to check in the costly discard from scratch packing rule?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "names = [f'from-scratch-{i}' for i in [0] + list(range(1, 20, 2)) if i != 3]\n",
    "names.append('default')\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['from-scratch-0']\n",
    "num_dfs = {\n",
    "    num: dfs['default' if num == 3 else f'from-scratch-{num}']\n",
    "    for num in range(1, 20, 2)\n",
    "}\n",
    "\n",
    "data = [\n",
    "    df.runtimes__total / base_df.runtimes__total for df in num_dfs.values()\n",
    "]\n",
    "\n",
    "with make_plot('from-scratch', (WIDTH_2COL, 2.5)) as (fix, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "    ax.set_xlabel(r'\\#Nodes checked')\n",
    "    ax.set_ylabel('Runtime (rel. to w/o rule)')\n",
    "    ax.set_xticks(range(1, len(num_dfs) + 1))\n",
    "    ax.set_xticklabels([str(num) for num in num_dfs.keys()])\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How often and when are better upper bounds found?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "df = get_df_hard_finished(\"default\")\n",
    "\n",
    "\n",
    "def bound_improvement_curve(row) -> List[Tuple[float, float]]:\n",
    "    bound_gap = row.root_bounds__greedy_upper - row.opt\n",
    "    if bound_gap == 0:\n",
    "        return [(0, 1), (1, 1)]\n",
    "    curve = [(0, 0)]\n",
    "    for impr in row.upper_bound_improvements:\n",
    "        rel_time = impr[\"runtime\"] / row.runtimes__total\n",
    "        rel_bound = 1 - (impr[\"new_bound\"] - row.opt) / bound_gap\n",
    "        curve.append((rel_time, rel_bound))\n",
    "    return curve + [(1, 1)]\n",
    "\n",
    "\n",
    "curves = [bound_improvement_curve(row) for row in df.itertuples()]\n",
    "x = np.array(sorted({x for curve in curves for x, _y in curve}))\n",
    "\n",
    "# Add slightly larger than 0 and slightly lower than 1 values, so that both 0 and 1\n",
    "# are only used for the very edges of the plot\n",
    "y = np.array(\n",
    "    sorted({y\n",
    "            for curve in curves for _x, y in curve} | {1e-12, 1 - 1e-12}))\n",
    "\n",
    "z = np.zeros((len(x), len(y)))\n",
    "rel = 1 / len(curves)\n",
    "for curve in curves:\n",
    "    for i in range(len(curve)):\n",
    "        x_left, curve_y = curve[i]\n",
    "        x_right = 2 if i + 1 == len(curve) else curve[i + 1][0]\n",
    "        x_l = np.searchsorted(x, x_left, side=\"left\")\n",
    "        x_r = np.searchsorted(x, x_right, side=\"left\")\n",
    "        y_r = np.searchsorted(y, curve_y, side=\"right\")\n",
    "        z[x_l:x_r, :y_r] += rel\n",
    "\n",
    "with make_plot('bound-updates', (WIDTH_1COL, 0.85 * WIDTH_1COL)) as (fig, ax):\n",
    "    contour = ax.contourf(\n",
    "        x,\n",
    "        y,\n",
    "        z.transpose(),\n",
    "        cmap=\"Greys\",\n",
    "        levels=np.linspace(0, 1, 11),\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "\n",
    "    # For some reason, the black polygon bugged out and leaves some white part\n",
    "    # in the bottom right undrawn. This just lays a black background behind the\n",
    "    # contour plot.\n",
    "    ax.fill([0, 0, 1, 1], [0, 1, 1, 0], facecolor=\"black\", zorder=-1)\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"Runtime\")\n",
    "    ax.set_ylabel(\"Upper bound progress\")\n",
    "\n",
    "    formatter = plticker.PercentFormatter(xmax=1)\n",
    "    ticks = np.linspace(0, 1, 6)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.tick_params(\"both\", labelsize=\"x-small\")\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    cbar = fig.colorbar(contour,\n",
    "                        ticks=ticks,\n",
    "                        format=formatter,\n",
    "                        fraction=0.046,\n",
    "                        pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=\"x-small\")\n",
    "\n",
    "    # Matplotlib by default cuts of the y-label, this mostly fixes the issue\n",
    "    fig.subplots_adjust(left=-0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Is it worth doing upper bounds during the algo?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "names = [\n",
    "    'default', 'greedy-never', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "base_df = dfs['greedy-never']\n",
    "data = [\n",
    "    dfs[name].runtimes__total / base_df.runtimes__total for name in [\n",
    "        'default',\n",
    "        'greedy-always-before-expensive-reductions',\n",
    "        'greedy-always-before-bounds',\n",
    "    ]\n",
    "]\n",
    "labels = [\n",
    "    'Once,\\nin the\\nbeginning', 'Every loop,\\nbefore expensive\\nreductions',\n",
    "    'Every loop,\\nbefore\\nbounds'\n",
    "]\n",
    "\n",
    "with make_plot('greedy-vs-off', (WIDTH_1COL, 2)) as (fig, ax):\n",
    "    ax.boxplot(data, **BOXPLOT_SETTINGS)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)) + 1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.tick_params(axis='both', which='major', labelsize='x-small')\n",
    "\n",
    "    ax.hlines(1, *ax.get_xlim(), **BACKGROUND_LINE_SETTINGS[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where do we put greedy?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "names = [\n",
    "    'default', 'greedy-always-before-bounds',\n",
    "    'greedy-always-before-expensive-reductions'\n",
    "]\n",
    "dfs = get_dfs_hard_finished(names)\n",
    "\n",
    "default_df = dfs['default']\n",
    "always_early_df = dfs['greedy-always-before-bounds']\n",
    "always_late_df = dfs['greedy-always-before-expensive-reductions']\n",
    "\n",
    "x = always_late_df.runtimes__total / default_df.runtimes__total\n",
    "y = always_early_df.runtimes__total / default_df.runtimes__total\n",
    "mx = round(1.1 * max(x.max(), y.max()), ndigits=1)\n",
    "\n",
    "with make_plot('where-greedy', (WIDTH_1COL, WIDTH_1COL)) as (fig, ax):\n",
    "    ax.scatter(x, y, **SCATTER_SETTINGS)\n",
    "\n",
    "    ax.set_xlabel('Every loop, before expensive reductions')\n",
    "    ax.set_ylabel('Every loop, before bounds')\n",
    "    ax.set_xlim((0, mx))\n",
    "    ax.set_ylim((0, mx))\n",
    "\n",
    "    for p1, p2 in [((0, 1), (mx, 1)), ((1, 0), (1, mx)), ((0, 0), (mx, mx))]:\n",
    "        ax.axline(p1, p2, **BACKGROUND_LINE_SETTINGS[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No instances were dropped (all finished in all experiments)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edfe6049ab5675c7b9b2a1e09418e73100ac83442bc85973e9f2e271101b608a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('findminhs-q4Va14KR': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}